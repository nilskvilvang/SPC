[["index.html", "Statistisk prosesskontroll Introduksjon", " Statistisk prosesskontroll Siste endring 18 oktober, 2021 Introduksjon Denne boka gir en introduksjon til statistisk prosesskontroll (SPC) som element i kontinuerlig kvalitetsarbeid. Innholdet er under kontinuerlig utvikling. Tilbakemeldinger og innspill bes gitt til Nils Kvilvang Bilde: Colourbox.com Boka er laget i R Markdown ved hjelp av en rekke programmer og pakker til R, ikke minst bookdown. "],["hvorfor-denne-boka.html", "1 Hvorfor denne boka? 1.1 Programvare", " 1 Hvorfor denne boka? Tanken på å lage denne boka oppsto gjennom forberedelser til innføring av et nytt emne i Kvalitetsledelse på Høgskolen i Innlandet, og gjennom erfaringer fra liknende kurs i helsesektoren rundt om i Kommune-Norge. Kvalitetsarbeid er et sentralt element i svært mange virksomheter. I mange virksomheter, som i helsesektoren, finnes det også lovpålegg som omhandler kvalitet. Det finnes et utall metodikker, tilbydere, bøker og artikler om temaet. Likevel følte vi at akkurat dette kompendiet manglet. Vi savnet en kobling mellom mye av det som blir beskrevet i bøker om kvalitet og kvalitetsledelse, og en grundigere behandling av grunnlaget (= datagrunnlaget) for mye av dette kvalitetsarbeidet. Denne koblingen var fundamental i utviklingen av kvalitetsarbeid gjennom frontfigurer som Walter A. Shewhart og W. Edwards Deming, men har etter vår mening til en viss grad havnet litt i bakleksa. Det grunnleggende premisset bak dette kompendiet og vår tilnærming til kvalitetsarbeid er: Uten en god forståelse av datagrunnlag og analyse av prosesser er sjansene for å lykkes med kvalitetsarbeid små og tilfeldige. I beste fall har man kastet bort ressurser. I verste fall har man kastet bort ressurser, økt frustrasjonen blant ansatte og fått dårligere kvalitet. Derfor mener vi at statistisk prosesskontroll må ha en helt sentral plass i kvalitetsarbeid. Dette kompendiet har til hensikt å drøfte kvalitetsarbeid. Vi mener dette notatet dekker et gap. For det første er det skrevet på norsk. Mye av litteraturen er skrevet på engelsk og kan for mange være vanskelig tilgjengelig av den grunn. Videre er det overraskende lite om statistisk prosesskontroll som verktøy i kvalitetsarbeid, langt mindre på norsk. Der det er et tema, er det i liten grad koblet inn i en større kvalitetssammenheng. Til slutt ønsker vi også å gi leseren en praktisk introduksjon gjennom å vise konkret anvendelse av statistisk prosesskontroll ved å bruke ulike dataverktøy. Til syvende og sist gjelder postulatet «godt gjort er bedre enn godt sagt». Det er vårt klare håp at denne boka kan være både en kilde til forståelse og et praktisk oppslagsverk. 1.1 Programvare Det kan synes unødvendig eller overflødig å vise bruk av flere dataverktøy, men hensikten er å gjøre dette lettere tilgjengelig og mer anvendbart for praktikere som har tilgang til ulike dataverktøy. Excel (Microsoft 2021) og R (R Core Team 2021)1 er fritt tilgjengelig (dvs Excel er for så vidt ikke fritt tilgjengelig, men så utbredt at det er naturlig å ta det med2). Det finnes veldig gode tilleggsprogrammer til Excel som integrerer seg sømløst med Excel3 og gjør at arbeidet med statistisk prosesskontroll blir veldig enkelt i et kjent grensesnitt. I forbindelse med arbeidet med denne boka har vi testet ut Analyse-It, SPC for Excel og QIMacros som gir Excel veldig god funksjonalitet4 5.6 Analyse-it kan fremstå som dyrt, men sammenliknet med ekte statistikkprogram er kostnaden relativt lav. Imidlertid finnes det veldig gode alternativer rettet spesielt mot statistisk prosesskontroll og kvalitetsarbeid. De to vi har testet ut er SPC for Excel og QIMacros. Begge integrerer seg sømløst med Excel, har all funksjonalitet man med veldig stor sannsynlighet vil trenge i denne sammenheng og er enkle i bruk. Men alle tilleggene utover standard Excel koster noe. Skal man jobbe en del med statistisk prosesskontroll med Excel som er det imidlertid vel verdt pengene mener vi  og i organisasjoner kan man få volumrabatter o.l. Selv om vi har laget videoer som forklarer framgangsmåte i Excel for flere av analysene og man fint kan lage ulike diagrammer selv, er det uten tvil mer krøkkete. Det er enormt tidsbesparende å ha en plug-in i Excel om man skal jobbe med statistisk prosesskontroll. Om man velger å skaffe seg et av tilleggene til Excel blir et spørsmål om hvor ofte man har behov for å gjøre dette. R (R Core Team 2021) er en velkjent programvare innenfor statistikk, dataanalyse, datamodellering osv. R har noen store fordeler; det er gratis, det kjører på alle operativsystemer, og det har et svært stort bruker- og utviklermiljø som i all hovedsak deler alt gratis. Det er også enkelt å finne løsninger på det meste gjennom veiledninger og brukerforum på nett. Selve R er et programmeringsspråk og utviklermiljø for statistikk som gir en kjernefunksjonalitet innenfor datahåndtering, kalkulasjoner, dataanalyse, datamodellering, grafisk framstilling av data o.l. Brukerne av R utvikler imidlertid pakker som man bruker i R, det finnes p.t. over 18000 ulike pakker som bygger på kjernen i R. Alle pakkene tilbyr ulike tilrettelagte løsninger  det finnes f.eks. flere pakker som spesifikt handler om statistisk prosesskontroll som qicharts2 og qcc. Den største ulempen med R er at brukergrensesnittet er veldig ulikt hva vi kjenner fra Microsoft Office-typen brukergrensesnitt, så det vil ta litt tid å bli kjent med programmet. I tillegg er brukergrensesnittet kodebasert og ikke menybasert, og kan (dessverre) virke avskrekkende. Likevel, det er et utrolig kraftig verktøy hvis man tar seg tid til å lære seg det grunnleggende. Et spesielt interessant gratis alternativ er statistikkprogrammet jamovi. Dette er en grafisk tiltalende og funksjonsrik statistikkpakke som kjører med R i bakgrunnen (alle analyser i jamovi bruker R), og som også kan inkludere R kode direkte. Det gjør at man kan utnytte alle pakkene skrevet for R direkte i jamovis grafiske brukergrensesnitt. Jamovi er et ypperlig gratis program for statistiske analyser, men har ingen innebygd funksjonalitet ennå for statistisk prosesskontroll (men man kan som sagt kjøre R-pakker for dette i programmet). Et annet ypperlig og gratis program er JASP som også kjører analyser gjennom R i et grafisk brukergrensesnitt, og som har den samme muligheten til direkte R integrasjon som jamovi  foreløpig i betaversjon. JASP er i tillegg i ferd med å utvikle en integrert modul for kvalitetskontroll/statistisk prosesskontroll. Det er forventet lansert i løpet av høsten 2021 og vil kunne bli den absolutt foretrukne plattformen siden den da vil kjøre både avanserte statistikkfunksjoner basert på R og SPC-funksjoner i et intuitivt og flott grensesnitt, og er gratis. Leseren står selvsagt fritt til å hoppe elegant over alle verktøy som ikke er interessante. Det er klare fordeler og ulemper med alle, men forhåpentligvis vil de fleste finne et verktøy de kan bruke i utvalget vi har tatt med. Der det er naturlig, som ved bruk av R og RStudio (Team 2021), er kodingen inkludert slik at eksempler skal kunne replikeres av leseren, men vi går ikke inn på R utover dette (og en veldig kort introduksjon til hvordan man laster ned og installerer R og RStudio). Kodingen er gjengitt i vedlegg. Vi har brukt R/RStudio og rmarkdown (Allaire et al. 2021)  en såkalt pakke til R  i produksjonen av dette notatet. R baserer seg som sagt på bruk av ulike pakker som er utviklet av forskjellige utviklere og som er fritt tilgjengelig. Mange av disse har også datasett inkludert slik at det er enkelt å replikere eksempler. Så langt det er mulig har vi basert oss på at det vi viser som eksempler skal være replikerbare for leseren. Når det gjelder pakker for statistisk prosess kontroll har vi brukt pakkene qicharts2 (Anhøj 2021) og qcc (Scrucca, Snow, and Bloomfield 2017). Vi har lite fokus på matematikk og formler i den forstand at vi ikke utleder i dybden forklaring på ulike formler. Vi tror det er fullt mulig å ha en praktisk forståelse og bruk av statistisk prosesskontroll uten å ha dyptgående kjennskap til de matematiske eller statistiske forklaringene  og det har vært vårt kjerneanliggende med denne boka. Likevel har vi inkludert noe bakgrunnskunnskap for å skape en ramme rundt kjernen i notatet der vi tenker det kan være interessant for de som ønsker å fordype seg noe mer. I vedleggene har vi også gjengitt formler og tabeller som kan være interessante. Strengt tatt bruker vi R og RStudio, men dette vil bli forklart i vedlegget som omhandler nedlasting og installasjon av disse. R er programvaren og motoren, RStudio er brukergrensesnittet vi legger utenpå R som gjør det langt enklere å bruke Vi viser til Excel, men man kan like gjerne bruke Apache Open Office, en gratis programvarepakke som inkluderer Calc. Videoene hvor vi viser framgangsmåte i Excel kan enkelt brukes med Calc (selv om mindre forskjeller kan eksistere). Vi er ikke kjent med tilsvarende tilleggsprogram for Open Office Calc. Et annet eksempel på tilsvarende tillegg til Excel er XLSTAT Analyse-It som inkluderer kvalitetsmodulen koster i skrivende stund $ 249 for en årlig lisens, eller $ 649 for en permanent lisens. Om man vil ha et gratis alternativ for statistiske analyser som legger seg i Excel kan også Real Statistics Resource Pack være et ok alternativ, men dette tillegget har ikke noen funksjonalitet for statistisk prosesskontroll "],["hvorfor-er-tid-viktig.html", "2 Hvorfor er tid viktig? 2.1 Hva er utgangspunktet vi skal korrigere fra?", " 2 Hvorfor er tid viktig? La oss anta at et sykehus har en prosess der man har registrert antall avvik gjennom året [^kap_2-1]. I 2019 hadde man 30 avvik i snitt pr måned. Ledelsen mente mot slutten av 2019 at dette var for høyt og bestemte at man skulle innføre en ny prosedyre fra årsskiftet. Ved overgangen til 2021 så man at man gjennom 2020 hadde ca. 24 avvik pr måned i snitt7 8: Download prepost_eksempel_long.xlsx Figure 2.1: Eksempel på prosess over 2 år Når man så nærmere på tallene kunne man også se at variasjonen mellom månedene var blitt mindre: Figure 2.2: Prosess over 2 år - spredning Dette er nok en kjent tilnærming og konklusjon for mange som har jobbet med eller i organisasjoner som gjør tiltak for å heve kvaliteten. Dessverre er det en tilnærming som i beste fall er unøyaktig, men som i verste fall tåkelegger hva som faktisk skjer og som over tid kan gi dårligere kvalitet. Problemet er at man ikke har sett dataene i et tidsperspektiv. Siden man har data for avvik hver eneste måned vil tidsperspektivet kunne gi helt andre innsikter og konklusjoner. Figure 2.3: Prosess over 2 år i et tidsperspektiv I diagrammet over har vi plottet inn hver enkelt måned slik at vi får en blå linje som viser utvikling fra måned til måned. Den oransje horisontale streken angir snittet for året (tilsvarende histogrammet lenger opp). Den røde vertikale streken angir årsskiftet og tidspunktet for endring av rutinen. Rent visuelt vil vi nå ha problemer med å konkludere med at endringen av rutinen var en suksess. Vi vil heller tenke at utviklingen gjennom 2019 var veldig positiv, men at endringen ved årsskiftet 2019-2020 har gjort at trenden nå er klart negativ ift at avvikene øker jevnt og trutt igjen. Så kan man spekulere i at det kanskje er innføring av ny rutine som gjør at man igjen får flere avvik og at på litt lengre sikt vil man ha en positiv effekt. Kanskje, det vil vi ikke se før tallene for 2021 begynner å tikke inn. Men det er grunn til å si at dersom man kunne se denne trenden etter 1.kvartal i 2020 hadde man kanskje vurdert tiltak for å endre trenden (eller i det minste gjort en grundig analyse av rutiner og tiltak). Eksempelet ovenfor er konstruert. Likevel er det grunn til å tro at det ikke er spesielt uvanlig. Mange vil nok kunne kjenne seg igjen i at det jobbes mye med kvalitet i ulike organisasjoner, men at man kanskje ikke har spesielt god kontroll på hva endringer gjør med prosesser, eller at man ikke klarer å fange opp tidsnok at utviklingen går i feil retning. Kanskje har man egentlig lite kontroll på selve prosessen før man starter en endringsprosess? Tidsaspektet er med andre ord et viktig aspekt å ha med seg, og helt essensielt i statistisk prosesskontroll som vi hevder bør ha en sentral plass i kvalitetsarbeid. 2.1 Hva er utgangspunktet vi skal korrigere fra? Det kan kanskje virke selvsagt, men en forbedringsprosess vil ha små og tilfeldige sjanser for å lykkes hvis vi ikke kjenner utgangspunktet. Vi vil påstå at mange slike prosesser likevel starter opp med et noe svakt kjennskap til hva startstedet egentlig er. Kvalitetsarbeid  forbedringsprosesser  startes som regel fordi man har en oppfatning av at det man leverer ikke er like godt som det man mener man kan og bør levere. Men hva er egentlig problemet? Er det treffsikkerheten (treffer vi målet, det vi sikter mot) eller konsistensen (klarer vi å repetere hendelsen gang etter gang), eller begge deler?9 Figure 2.4: Kjenne til utgangspunktet før vi gjør endringer Det er ganske innlysende at vi vil ha langt større sannsynlighet for å lykkes med en forbedringsprosess om vi har kontroll på hva startsituasjonen er. Her kommer statistisk prosesskontroll inn og kan være et viktig verktøy. Med unntak av den nedre høyre illustrasjonen, der både treffsikkerhet og konsistens er bra, viser alle målskivene en variasjon i hvordan treffene er. Variasjon er et essensielt begrep i statistisk prosesskontroll, og forståelse av variasjon vil følgelig være et viktig tema før vi gir oss i kast med selve analysene. Uten forståelse av prosess og variasjon er det fare for at man forsøker å justere en prosess på feil grunnlag, og i verste fall ville vi kommet bedre ut av endringsprosessen ved å ikke gjøre noe som helst. Eksempelet er modifisert fra Carey (2003). Se også Anhøj (2009) og NHS (2009) Hvis du ønsker å bruke R og koden må du laste ned fila og lagre den i samme mappe som din R-fil/ditt R-prosjekt ligger - se forøvrig vedlegg om installasjon av R/RStudio for tips om organisering av filer Illustrasjonen er modifisert fra Montgomery (2020), jfr. Leavengood and Reeb (2015) "],["variasjon.html", "3 Variasjon 3.1 Simulering av trakteksperimentet i R", " 3 Variasjon Vi skal tilnærme oss begrepet variasjon gjennom å vise til et velkjent eksperiment  «The Funnel Experiment», eller trakteksperimentet som vi kan kalle det på norsk. Hensikten med trakteksperimentet var å vise at dersom vi ikke forstår variasjon, og introduserer korrigerende tiltak i prosesser som ikke trenger det, står vi i fare for å forverre resultatet (og ofte ha brukt mye tid og ressurser på å justere prosessen i den tro at resultatet vil bli bedre). Eksperimentet illustrerer at mange tiltak i organisasjoner for å «rette på feil» eller «forbedre kvaliteten» ender opp med å ha motsatt virkning. Trakteksperimentet - oppsett Trakteksperimentet ble popularisert av Deming (1986) for å beskrive de negative effektene prosessendringer kan ha hvis man ikke forstår årsakene til variasjonen i resultatene (Deming krediterer selv Lloyd Nelson for å ha designiet ekseperimentet, og enkelte kilder omtaler derfor dette som the Deming-Nelson funnel experiment (Georgantzas and Orsini 2003) . I trakteksperimentet lar vi en klinkekule falle gjennom en trakt vi har sentrert rett over et mål. Der kula treffer arket setter vi et merke. Kula vil aldri treffe nøyaktig på målet og aldri nøyaktig på samme sted fra gang til gang. La oss si at vi slipper kula gjennom trakta første gang. Trakta er plassert slik at senterlinja gjennom trakta treffer nøyaktig midt i målet. Så slipper vi kula og registerer treffpunktet. Trakteksperimentet - oppsett Deretter bruker vi 1 av 4 regler for korreksjon for å justere prosessen for å forsøke å få kula til å treffe nærmere målet (se f.eks. (Sparks and Field 2000). Regel 1 Ingen justering. Selv om kula ikke treffer målet fortsetter vi med neste forsøk uten å gjøre noen justeringer. Vi holder trakta på nøyaktig samme sted. Regel 2 Trakta justeres etter forrige treffpunkt (treff 1). Hvis kula treffer i z avstand fra målets senterpunkt vil trakta justeres med -z før neste forsøk. Trakteksperimentet - treff etter første forsøk Så gjentar vi prosessen og korrigerer trakta fra traktas forrige posisjon etter hvert treffpunkt ut fra kulas avstand fra det nye treffpunktet til målets senterpunkt. Justering av trakta skjer etter følgende metode: Plassering av trakta starter i målsenteret (0,0) og justeres deretter slik at ny plassering blir målsenteret blir minus offset (retning og avstand) for forrige kule fra treffpunkt til målsenteret. Sparks and Field (2000) beskriver regelen slik: At drop i (i = 1,2,3, .) the marble will come to rest at point yi, measured from the target. (In other words, yi is the error at drop i.) Move the funnel the distance -yi from its last position to aim for the next drop. Deming (1986) gir noen eksempler på bruk av regel 2: feedback-mekanismer som reagerer på enkelttilfeller, endring av en policy, rutine e.l. på bakgrunn av (kun) siste kundeundersøkelse, bruke variasjon/avvik til å lage budsjetter og vurdering av en aksje basert på forrige måneds underskudd. Regel 3 Her registrerer vi treff 1 som i regel 2. Vi flytter trakta til et punkt nøyaktig motsatt av det punktet kula fikk. Vi beregner offset for kula på samme måte som i regel 2  retning og avstand fra målsenteret til kulas treffpunkt. Før vi justerer flytter vi imidlertid trakta tilbake til (0,0) og justerer derfra (i motsetning til regel 2 da vi ikke flyttet trakta til (0,0) før vi begynte korreksjonen, men i stedet foretok justeringen fra det punktet trakta befant seg da kula ble sluppet). Her eksemplifiserer Deming (1986) ved å vise til hvordan mer effektiv narkotikabekjempelse fører til høyere priser på narkotika som stimulerer til smugling av mer narkotika, eller en gambler som høyner innsatsen for å dekke forrige tap. Sparks and Field (2000) beskriver regelen slik: At drop i the marble comes to rest at point yi from the target, then for the next drop aim the funnel over the point -yi from the target. Regel 4 Her flytter vi trakta hele tiden til siste treffpunkt og slipper ny kule der. Her viser Deming (1986) til eksempler som den kjente «hviskeleken» der et antall personer sitter i en ring og gjenforteller en historie ved å hviske den til neste person, som igjen hvisker den til neste osv til den kommer til siste person som forteller historien vedkommende nettopp hørte. Historien som til slutt blir fortalt er som regel ganske annerledes enn den opprinnelige. Et annet eksempel kan være produksjon av en gjenstand basert på forrige produserte gjenstands mål. Sparks and Field (2000) beskriver regelen slik: At drop i the marble comes to rest at point yi from the target, then for the next drop aim the funnel over the spot yi where the marble last came to rest. En kort og instruktiv video (Crostic 2015) om gjennomføringen av trakteksperimentet vises kan dere se her. 3.1 Simulering av trakteksperimentet i R Vi kan kjøre en simulasjon som viser at resultatet blir suksessivt dårligere etter hvert som vi implementerer reglene. Best resultat kommer fra ingen justering. Dernest gir regel 2 nest best resultat, regel 3 nest dårligst, og til slutt regel 4 det dårligste resultatet. Ved en simulering av 100 repetisjoner kan vi grafisk se hvilket resultat vi får gjennom å anvende de fire ulike reglene. For å kjøre R-koden (jfr vedlegg) må du laste ned disse Excel-filene: Download Funnel_blankedata_regel3.xlsxDownload Funnel_blankedata_regel4.xlsx Figure 3.1: Simulering av trakteksperimentet Det vi kan se er at resultatet etter regel 1 og 2 er sentrert rundt målet, men at regel 2 gir større spredning. Simuleringer viser at regel to gir 40-41 % større areal i plottet  eller dobbelt så stor varians (Prevette 2008; SPC for Excel 2006).10 Regel 3 vil gi et økende oscillerende mønster. Med en start i nærheten av målet (0,0) vil treffpunktene flytte seg fra side til side stadig lengre vekk fra målet. Mønsteret vil variere, men treffpunktene vil stadig flytte seg lenger unna målet. Hvis vi har et annet førstetreff, vil dette påvirke hvordan mønsteret utvikler seg. For å kjøre R-koden for alternativt førstetreffpunkt må du laste ned denne Excel-fila: Download Funnel_blankedata_regel3_2.xlsx Figure 3.2: Regel 3 - annet førstetreff Regel 4 vil alltid medføre at treffpunktet vil bevege seg lenger og lenger unna målet. Med et annet førstetreff vil mønsteret se annerledes ut. For å kjøre R-koden for alternativt førstetreffpunkt må du laste ned denne Excel-fila: Download Funnel_blankedata_regel4_2.xlsx Figure 3.3: Regel 4 - annet førstetreff Eksperimentet, som altså som regel refereres til som Demings trakteksperiment (Funnel experiment), men refereres også som Nelsons trakteksperiment (se f.eks. Alwan (1991)) illustrerer en viktig erkjennelse i alt kvalitetsarbeid: hvis man ikke vet hva man driver med kan man i beste hensikt fort ende opp med å korrigere en prosess ut i evigheten vekk fra målet. Dessverre er det grunn til å tro at mange forbedringsprosesser ender opp på denne måten. Eksperimentet illustrerer videre en viktig observasjon: alle prosesser har variasjon. Hvis vi tenker over det, vil vi lett finne eksempler fra dagliglivet. Vi sover et antall timer og minutter sammenhengende søvn hver natt som ikke vil være det samme fra natt til natt, men som regel ligge innenfor et visst intervall. Vi har en hvilepuls når vi våkner om morgenen. Måler vi den vil vi se variasjon. Vi kjører til jobben, og tidsbruken vil variere fra dag til dag. Vi tar en treningstur på kvelden. Selv om vi løper samme runde med samme utstyr vil tiden vi bruker variere. Eller strømregningen vi betaler hver måned. Hva med kostnader for en sykehusavdeling? Antall overtidstimer i en organisasjon? Mengde materialer i en bestemt produksjonslinje? Alle de ovennevnte er prosesser som har en variasjon. Variasjon kan være normal eller unormal. Med normal variasjon mener vi variasjon som ikke kan tilskrives en spesiell årsak (ofte omtalt som common cause variation og opprinnelig av Shewhart som assignable cause). Tilsvarende kan unormal variasjon tilskrives en eller flere spesifikke årsaker (special cause variation, av Shewhart benevnt som chance cause). Normal variasjon skyldes fenomen som alltid er til stede i en prosess, og kan dermed ikke endres uten at man endrer selve prosessen. Det betyr også at normal variasjon er det som gjør prosesser forutsigbare i større eller mindre grad. Unormal variasjon på sin side skyldes en (eller flere) ikke-tilfeldige påvirkninger som ikke vanligvis er til stede i prosessen. Dette gjør prosessen uforutsigbar. Problemene oppstår når man ikke skiller mellom de to typene variasjon, og jager etter spesielle årsaker til variasjon når det i realiteten kun er normal variasjon man observerer. Da jager man etter å løse problemer uten å forstå årsakene. La oss se på dataene fra trakteksperimentet igjen, og denne gangen skal vi plotte datapunktene på en måte som gjør at vi ser hvordan treffpunktene varierer ved at vi plotter på en tidsakse (første forsøk til venstre, siste til høyre på x-aksen). Vi kan først se på treffpunkter for x- og y-verdi for hhv regel 1 og 2. Figure 3.4: x- og y-verdier for regel 1 Figure 3.5: x- og y-verdier for regel 2 Det vi kan se er: * Mønstrene likner på hverandre i hvordan de varierer * De varierer like mer eller mindre like mye over og under x = 0 og y = 0. En absolutt perfekt prosess ville gitt null avvik fra 0,0 for hvert forsøk. Dette tyder på at variasjonen er sentrert rundt målpunktet. * Vi kan se at avviket er noe større for regel 2, spesielt på x-verdiene. Dette er iht forventning siden vi vet at variansen er dobbelt så stor for regel 2 som for regel 1. * Vi ser også at gjennomsnittet (markert med horisontal linje) er nærme 0 for både x- og y-verdi for regel 1, mens den er noe mer avvikende for begge verdiene for regel 2. Hvis vi ser på x- og y-verdiene for regel 3 får vi et helt annet bilde. Figure 3.6: x- og y-verdier for regel 3 Vi ser at vi får en økende oscillerende trend. Samtidig ser vi at treffene er sentrert rundt 0, men at treffpunktene i stadig økende grad fjerner seg fra 0. Mønsteret er også veldig likt for x-verdi og y-verdi. Til slutt kan vi se på regel 4. Figure 3.7: x- og y-verdier for regel 4 Det vi kan legge merke til er at begge verdiene starter nærme 0, men at de  som forventet  etter hvert fjerner seg i en trend vekk fra 0. Hadde man kjørt 1000 eller 10000 forsøk ville denne trenden vært enda tydeligere. Dette leder oss til to begrep som er vesentlige i kvalitetsarbeid. Er prosessen kontrollert («in control») eller er den ukontrollert («out of control»)? Prosesser med kun normal variasjon er kontrollerte prosesser, mens prosesser med unormal variasjon er ukontrollerte prosesser. I en kontrollert, stabil prosess er årsakene til variasjon i ytelse/resultater konstant over tid. Dette betyr altså ikke at det ikke er variasjon i ytelse/resultater/kvalitet, at variasjonen er liten eller at kvaliteten er god nok. Under har vi simulert to team som jobber parallelt med å produsere samme produkt, samme maskiner, med samme råmaterialer. Vi skal ikke gå nærmere inn på variasjon o.l., men kan kort konstatere at begge prosessene er i kontroll. Vi kommer tilbake til kontrollgrenser om kort tid, men kort fortalt må alle punkter ligge innenfor kontrollgrensene for at prosessen skal være i kontroll. For å kjøre R-koden må du laste ned følgende fil: Download toteam.xlsx Figure 3.8: To teams kontrolldiagrammer Imidlertid ser vi at Team 1s prosess har større variasjon enn team 2s (selv om de ser like ut må vi ta hensyn til at y-aksene er ulike (legg merke til verdiene 1,2 og 0,4 som viser den øvre kontrollgrensen. Vi ser også at gjennomsnittet ligger på hhv 0.5 og 0.1 for team 1 og 2. Dersom vi arrangerer plottene med samme skala på y-aksen ser vi en klar forskjell mellom de to teamene: Figure 3.9: To teams - like prosesser - ulik variasjon Vi trenger altså ikke være fornøyde med en stabil og kontrollert prosess. Det betyr bare at variasjonen er forutsigbar innenfor statistisk etablerte grenser (Nolan and Provost 1990), og at ytelsen fra prosessen ikke vil endre seg vesentlig med mindre man endrer selve prosessen.Begge prosessene over er kontrollerte, men det kan virke åpenbart at man vil se nærmere på hvorfor det ene teamet skiller seg veldig fra det andre. Arbeidet med statistisk prosesskontroll handler i hovedsak om dette: Forstå prosessen og forstå variasjonen. Trakteksperimentet viser oss også at korreksjon av prosesser kan lede oss lenger og lenger fra målet om vi ikke forstår variasjon og kontrollerte vs. ukontrollerte prosesser. Deming omtaler dette som «tampering with the process» - tukling med prosessen («If it aint broken, dont fix it»). I jakten på små forbedringer er det fristende å gjøre små justeringer ofte. Det kan være en smart strategi, men det kan også gi motsatt effekt: variasjonen i resultatene blir bare større og større (i takt med desperasjonen etter ønskede forbedringer). Dette vil vi kalle for over-kontrollering av prosesser. Erkjennelsen av variasjon i prosesser og om prosesser i kontrollert eller ukontrollert har klare ledelsesmessige utfordringer og konsekvenser. Nolan and Provost (1990, s.3, figur 1) illustrerer to ulike tilnærminger til variasjon: .tabwid table{ border-spacing:0px !important; border-collapse:collapse; line-height:1; margin-left:auto; margin-right:auto; border-width: 0; display: table; margin-top: 1.275em; margin-bottom: 1.275em; border-color: transparent; } .tabwid_left table{ margin-left:0; } .tabwid_right table{ margin-right:0; } .tabwid td { padding: 0; } .tabwid a { text-decoration: none; } .tabwid thead { background-color: transparent; } .tabwid tfoot { background-color: transparent; } .tabwid table tr { background-color: transparent; } .cl-e0a6be90{table-layout:auto;width:100%;}.cl-e08827e6{font-family:'Arial';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-e08875c0{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-e088eaa0{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-e088eaa1{background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-e088eaa2{background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} OmråderVariasjon1Variasjon2Som indikator på god eller dårlig ytelseSom resultat av normal eller unormal variasjonFokusResultat av prosessen (produkt, tjeneste)Årsaker til variasjon i prosessenMålKlassifisere resultat som akseptabelt eller ikkeGi grunnlag for endring av prosessGrunnlagHva kunden ønsker eller trengerHva prosessen faktisk girMetoderMetoder&emsp;Spesifikasjoner, budsjetter, prognoser, numeriske mål, verktøy for å måle ytelseKontrolldiagram En klar svakhet ved den første tilnærmingen  som indikator på god eller dårlig ytelse  er at det tilbyr lite informasjon og grunnlag for forbedring. Likevel, mange vil nok kjenne seg igjen i fokus, mål, grunnlag og metoder i denne tilnærmingen. En kjerne i ledelse i organisasjoner må derfor være å kunne avgjøre om variasjonen fra ulike prosesser er normal eller unormal, og om svingninger indikerer en trend eller en tilfeldig variasjon som følger mønstre vi har sett tidligere. Nolan and Provost (1990) peker på mulige konsekvenser i organisasjoner av å trekke feilslutninger om variasjon: Skylden for problemer legges på ansatte som er utenfor deres kontroll, kostnader til nytt utstyr som ikke er nødvendig, bortkastet tidsbruk for å lete etter forklaringer på en antatt trend når ingenting egentlig har endret seg og gjennomføre tiltak når det ville ha vært bedre å ikke gjøre noe. modifisert fra Nolan &amp; Provost, 1990, s.9, figur 2 Deming (1986) peker på at det store rommet for forbedring (94 %) ligger i endring av prosessen  altså i å jobbe med den normale variasjonen (gitt at prosessen er stabil). Kun 6 % av potensialet ligger i å fikse spesielle ting  unormal variasjon  som skjer. Her ser vi en veldig klar kobling til ledelsesaspektet og ledelsesansvaret som ligger i å realisere potensialet for forbedringer. Matematisk sett vil standardavviket ved å legge til n uavhengige tilfeldige observasjoner øke med kvadratroten av n ganger standardavviket for den individuelle observasjonen. Samlet sett dobles variansen, hvilket gir 1,4 ganger høyere standardavvik (siden standardavvik er kvadratroten av variansen, og \\(\\sqrt{2}\\) \\(\\approx\\) 1.4 "],["datatyper-og-datafordelinger.html", "4 Datatyper og datafordelinger 4.1 Normalfordeling 4.2 Binomialfordeling 4.3 Poissonfordeling 4.4 Geometrisk fordeling 4.5 Eksponensiell fordeling", " 4 Datatyper og datafordelinger Ift statistisk prosesskontroll er det formålstjenlig å snakke om tre hovedtyper data: måledata, telledata og sjeldne hendelser. Måledata er kontinuerlige data  det vil si de kan måles på en skala som høyde, vekt og tid. Her kan en observasjon/et datapunkt innta en hvilken som helst verdi innenfor et gitt spenn. Høyden på en person kan være 178,34227809 cm eller 178,34227808 cm. Telledata et kategoriske (også ofte omtalt som diskrete) data  det vil si et datapunkt (en observasjon) kan puttes inn i en klar kategori, som f.eks. antall avvik, antall hendelser, ja/nei, terningkast. Diskrete data har et begrenset antall mulige verdier som er gjensidig utelukkende. Et terningkast med en vanlig terning kan ikke både være 3 og 4 samtidig, en lysbryter kan ikke være av og på samtidig. Et terningkast kan heller ikke være 1,43. Med tanke på datafordeling er både binomial-, Poissonfordeling og geomterisk fordeling diskrete fordelinger, mens normalfordeling og eksponensiell fordeling vil være kontinuerlig (se f.eks. Ugarte, Militino, and Arnholt (2016)). Når det gjelder sjeldne hendelser kan de være både telledata og måledata. For eksempel vil antall dager mellom en hendelse være en diskret data, mens tid kan måles og vil være kontinuerlige data. Det er spesielle utfordringer med det vi kaller sjeldne hendelser finnes det også egne måter å håndtere dette på i statistisk prosesskontroll, noe vi vil komme tilbake til. For sjeldne henselser vil både geometrisk og eksponensiell fordeling være relevant. Det finnes en god del flere fordelinger enn disse som nå er nevnt, men som Benneyan (1998) viser er normal-, binomial- og Poissonfordeling de tre vesentligste. For en god oversikt over flere fordelinger, se f.eks. Mun (2008). Hvorfor fokus på fordelinger? Fordelingene  normalfordeling, binomialfordeling, Poissionfordeling, geometrisk fordeling og eksponensiell fordeling  beskriver ulike fordelinger ut fra hvordan dataene ser ut. Vi bruker forventningene/sannsynlighetene for ulike verdier i statistisk prosesskontroll til å vurdere om en verdi av en observasjon eller måling er innenfor eller utenfor det vi vil kalle normal variasjon (jfr kapittelet om variasjon). Siden dataene kan være av ulik type  diskret eller kontinuerlig, binomial/ikke binomial osv  bruker vi ulike utregningsmetoder og diagrammer i statistisk prosesskontroll for å få et riktig resultat. Det finnes et antall ulike diagrammer å velge mellom i statistisk prosesskontroll. For å gjøre valget sikrere og lettere kan man bruke følgende flytskjema for å orientere seg: Flytdiagram for valg av analyse Senere kommer vi tilbake til de ulike diagrammene gjennom praktiske eksempler. Før vi kommer dit vil vi gå gjennom de sentrale datafordelingstypene. 4.1 Normalfordeling Når vi snakker om distribusjonen av et datasett tenker vi på hvordan dataene vi har samlet inn fordeler seg i forhold til hverandre etter gitte egenskaper. Vi kan for eksempel ha målt høyden på 100 mennesker. Disse dataene utgjør da en observert fordeling som vi kan sette inn i et diagram for å visualisere hvordan datasettet ser ut. Figure 4.1: Høydefordeling for 100 tilfeldige menn, genererte data Hvis vi samler inn høydedata for 100 andre tilfeldig menn kan fordelingen se slik ut: Figure 4.2: Høydefordeling for 100 andre tilfeldige menn, genererte data Hver gang vi måler høyden på 100 tilfeldig utvalgte menn vil fordelingen se ulik ut siden de er observerte fordelinger i et utvalg av populasjonen (alle) «norske menn». Hvis vi imidlertid økte antallet i utvalget vi målte til 1000 eller 10000 vil vi med større sikkerhet kunne si at vi faktisk viser populasjonens fordeling (mulighetene for at vi tilfeldigvis måler 10000 veldig lave eller veldig høye menn er svært liten). Vi kan derfor, gitt visse forutsetninger om utvalget, si noe om hele populasjonen ut fra utvalget. Hittil har vi snakket om observerte fordelinger. Ut fra dette kan vi si at vi kan ha visse forventninger til hvordan fordelingen av ulike populasjoner vil se ut, og vi kan snakke om teoretiske fordelinger  eller sannsynlighetsfordelinger med andre ord. Hvor sannsynlig er det at en tilfeldig x-verdi dukker opp i dataene? For høyde kan vi ha visse forventninger til hvilke sannsynligheter det er for at en tilfeldig person har en gitt høyde, eller hvor mange prosent av den mannlige befolkningen som har en høyde innenfor et gitt intervall. Det vil si at fordelingen har en viss form med visse karakteristika. Vi forventer at flest observasjoner befinner seg i nærheten av gjennomsnittet, og at vi vil se færre og færre observasjoner jo lenger unna gjennomsnittet vi beveger oss. Vi forventer å finne flere norske menn over 20 år på rundt 180 cm enn 160 cm eller 210 cm. For fordelingen av høydedata vil vi si at dette er data som er normalfordelte. En normalfordeling er en sannsynlighetsfunksjon der flesteparten av verdiene fra funksjonen samler seg om en sentral tendens, og der tettheten (hyppigheten) av verdier avtar jevnt jo lenger unna den sentrale tendensen man kommer. Grafisk framstilt får fordelingskurven en klokkeform, og normalfordeling omtales også som bell shaped. Overraskende mange fenomener viser seg å være nærme en normalfordeling, og den er derfor en helt sentral teoretisk sannsynlighetsfordeling i mange sammenhenger (også i statistisk prosesskontroll som vi kommer tilbake til senere). Vi bruker dermed normalfordelingen som en modell for observerte data. I en såkalt standard normalfordeling har vi en symmetrisk fordeling der den sentrale tendensen (forventingen) verdi = 0 og et standardavvik = 1. Vi skal her ikke bry oss om det matematisk uttrykket for sannsynlighetstetthetsfunksjonen. Hvis vi derimot genererer et tenkt datasett etter standard normalfordelingsfunksjon vil det kunne se slik ut: Figure 4.3: Genererte standard normalfordelte data Her kan vi legge på en forventningskurve  en teoretisk kurve som viser en standard normalfordeling: Figure 4.4: Genererte standard normalfordelte data med normalfordelingskurve Vi kan ta bort det genererte datasettet og sitte igjen med bare normalfordelingskurven: Figure 4.5: Normalfordelingskurve Det den standardiserte normalfordelingskurven (også kjent som Gausskurven eller også Bellkurven  Klokkekurven fordi den har en klokkeform)  kan brukes til er å si noe om spredningen på forventede verdier  eller hvor langt fra gjennomsnittsverdien man kan forvente å finne de enkelte verdiene. Før vi ser nærmere på egenskaper ved normalfordelingskurven kan det være nødvendig å gå litt inn på begrepene varians og standardavvik som mål på spredningen i datasett. Disse begrepene, spesielt standardavvik, vil være helt sentrale i videre arbeid med temaet. 4.1.1 Varians og standardavvik Variansen i en variabel representerer det gjennomsnittlige avviket fra gjennomsnittsverdien (Field, Miles, and Field 2012) og er et mål på spredningen i dataene (som navnet antyder: hvor mye dataene variere ut fra den sentrale tendensen). Under vises et eksempel basert på Field (2009). La oss anta at vi har spurt 5 studenter på høgskolen hvor mange kjæledyr de har. Svarene kan settes opp i en enkel tabell. I gjennomsnitt har de 2,6 kjæledyr. Vi ønsker imidlertid å se hvor mye avviket er for den enkelte fra snittet (siden vi har regnet ut snittet kan vi se på gjennomsnittsverdien som en modell på forholdet mellom studenter og antall kjæledyr). Vi registrerer svarene vi fikk i et skjema: .tabwid table{ border-spacing:0px !important; border-collapse:collapse; line-height:1; margin-left:auto; margin-right:auto; border-width: 0; display: table; margin-top: 1.275em; margin-bottom: 1.275em; border-color: transparent; } .tabwid_left table{ margin-left:0; } .tabwid_right table{ margin-right:0; } .tabwid td { padding: 0; } .tabwid a { text-decoration: none; } .tabwid thead { background-color: transparent; } .tabwid tfoot { background-color: transparent; } .tabwid table tr { background-color: transparent; } .cl-e2172c7e{table-layout:auto;width:100%;}.cl-e1e5691e{font-family:'Arial';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-e1e60504{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-e1e6a0cc{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-e1e6a0cd{background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-e1e6a0ce{background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} StudentnrAntallAvvikAvvik_kvadrert11-1.62.5622-0.60.36330.40.16430.40.16541.41.96Snitt2.6Sum05.20 Når vi regner ut avviket (sum of deviances) summerer vi avvikene. Siden denne er 0 skulle det innebære at det totalt sett i modellen ikke er avvik mellom modellen og våre virkelige observasjoner. Problemet her er at det er både positive og negative avvik som nuller hverandre ut. Man må derfor kvadrere avvikene for å omgå problemet med fortegn. Imidlertid får vi et nytt problem. La oss anta at vi i stedet for 5 studenter har spurt 500. Da får vi et svært høyt kvadrert avvik fra snitt. Altså  vi må ta høyde for for antallet observasjoner. Vi deler derfor sum kvadrert avvik fra snitt på antall observasjoner (5,20/5). MEN: vi må foreta et litt teknisk og komplisert tillegg i utregningen. Vi må dele på antall observasjoner MINUS 1 (som er antallet frihetsgrader  degrees of freedom). Dette vil ikke bli nærmere forklart her, men for de som ønsker å lese mer om frihetsgrader kan prøve noen andre kilder, f.eks. Walker (1940), Good (1973) eller Pandey and Bright (2008). Vi ender altså opp med regnestykket 5,20/(5-1) = 1,3. Dette er variansen. Variansen er altså det gjennomsnittlige avviket mellom gjennomsnittsverdien av de observerte dataene og verdiene til de enkelte observasjonene. Som regel snakker vi imidlertid om standardavviket. Dette finner vi ved å ta kvadratroten av variansen (som vi jo har funnet ved å kvadrere avvikene for å unngå fortegnsproblemer). Vi får da i vårt tilfelle et standardavvik på 1,14. Variansen og standardavviket forteller oss altså noe om spredningen i dataene. Liten varians betyr at spredningen er liten (om vi har gjennomført en spørreundersøkelse betyr det at respondentene har svart ganske likt). Stor varians betyr stor spredning (respondentene har svart ganske ulikt). 4.1.2 Normalfordeling, standardavvik og forventninger Vi kan nå se nærmere på normalfordelingen. Figure 4.6: Normalfordeling med 1 standardavvik Ett standardavvik over og under 0 (= det skraverte området i grafen over) innebærer at det er 68 % sannsynlighet for at en tilfeldig valgt x-verdi befinner seg i dette intervallet. Vi kan vise det samme for 2 og 3 standardavvik: Figure 4.7: Normalfordeling med 2 standardavvik To standardavvik over og under 0 (= det skraverte området i grafen over) innebærer at det er 95 % sannsynlighet for at en tilfeldig valgt x-verdi befinner seg i dette intervallet. Vi kan finne arealet mellom x=-2 og x=2, som er 0.954499711. Figure 4.8: Normalfordeling med 3 standardavvik Tre standardavvik over og under 0 (= det skraverte området i grafen over) innebærer at det er 99.7 % sannsynlighet for at en tilfeldig valgt x-verdi befinner seg i dette intervallet. Vi kan finne arealet mellom x=-3 og x=3, som er 0.997300212. Dette utgjør et kjernepunkt i statistisk prosesskontroll som vi vil komme mye tilbake til. Oppsummert kan vi framstille normalfodeling og standardavvik slik (Hartmann, Krois, and Waske 2018): Figure 4.9: Normalfordeling med standardavvik Som nevnt er mange fenomener i hverdagen normalfordelte, eller nærme nok normalfordeling til at vi kan bruke normalfordeling som teoretisk modell for observerte data.13 Det finnes imidlertid mange tilfeller der vi ikke kan bruke normalfordelingen. Hvis dataene er sterkt asymmetriske vil ikke reglene for normalfordeling som vi har skissert ovenfor gjelde.14 Noen av de er viktige for statistisk prosesskontroll, og de vil vi se på i de følgende avsnittene. 4.2 Binomialfordeling En distribusjon hvor det kun er to mulige utfall av en hendelse kalles en binomial fordeling. Et myntkast er en slik hendelse (gitt at vi ser bort fra den fysiske muligheten at mynten kan lande stående på høykant). Levende eller død kan også være et eksempel på dette. Det ene utfallet utelukker det andre, men de er uavhengige fordi resultatet i ett myntkast ikke påvirker resultatet i neste myntkast. Alle myntkastene må derimot være identiske, det vil si sannsynligheten for det ene eller det andre resultatet er lik hver gang forsøket eller myntkastet gjennomføres. Hvis vi har lik sannsynlighet, kan en tilfeldig generert binomial distribusjon se slik ut: Figure 4.10: Binomialfordeling med lik sannsynlighet I diagrammet over vises en sannsynlighetsfordeling for en binomial fordeling der utfallene suksess/fiasko har lik sannsynlighet. Hvis vi gjennomfører en aktivitet med disse karakteristika 20 ganger kan vi bruke sannsynlighetsfordelingen til å skape en forventning om sannsynligheten for antall suksesser/fiaskoer. Hver gang vi gjennomfører aktiviteten blir det enten suksess eller fiasko. Hvis vi har 50% sjanse for suksess eller feil hver gang vi gjennomfører aktiviteten er sannsynligheten for suksess lik som sannsynligheten for fiasko. Vi kan da forvente at det er størst sannsynlighet at vi i 10 av 20 tilfeller får suksess. Det er liten sannsynlighet for at vi enten får suksess i 0 eller 20 av 20 ganger vi gjør aktiviteten. Det er imidlertid verdt å merke seg at de to utfallene ikke trenger å ha lik sannsynlighet. Da vil den binomiale distribusjonen se annerledes ut: Figure 4.11: Binomialfordeling med ulik sannsynlighet Her har vi bare 20% sannsynlighet for suksess, og fordelingen av sannsynligheter vil se annerledes ut. Med 20% sannsynlighet for suksess er det veldig liten sannsynlighet for at vi vil få 10 eller flere suksesser hvis vi gjør forsøket 20 ganger. Det er størst sannsynlighet for å få 4 suksesser. Et terningkast (med en vanlig terning med 6 sider)  som ikke er tuklet med  har lik sannsynlighet for å lande på hhv 1,2,3,4,5 og 6. Det vil si det er 1/6 sannsynlighet for 1, 1/6 sannsynlighet for 2 osv. Hvis vi kaster denne terningen 10 ganger kan resultatet se slik ut: Figure 4.12: 10 terningkast Vi ser at vi ikke fikk noen 2ere og 5ere. Dette kan vi forvente når vi bare har 10 terningkast. Hvis vi imidlertid kaster terningen 100 ganger vil det være svært liten sannsynlighet for å ikke få «treff» på alle 6 verdiene på terningen, og vi burde kunne forvente at vi får en ganske jevn fordeling på alle 6 verdiene. Nedenfor vises resultatet av 100 terningkast. Figure 4.13: 100 terningkast Vi ser at vi har en relativt jevn fordeling. Noe ulikhet er det selvsagt, noe vi vil forvente fra en tilfeldig prosess. Hvis vi gjennomførte 1000 eller 10000 terningkast vil fordelingen bli nærmere og nærmere den teoretisk forventede fordelingen. Vi kan burde, teoretisk, forvente 100 treff på hver mulighet hvis vi kaster terningen 600 ganger, men vi vil sjelden se akkurat 100 treff på hver slik vi ser hvis vi kjører tre runder med 600 terningkast: Runde 1: ## terning_runde1 ## 1 2 3 4 5 6 ## 93 102 102 102 108 93 Runde 2: ## terning_runde2 ## 1 2 3 4 5 6 ## 101 102 94 91 105 107 Runde 3: ## terning_runde3 ## 1 2 3 4 5 6 ## 104 113 92 98 95 98 Selv om vi kjører 6 000 000 terningkast og vil forvente 1 000 000 treff på hver av terningens sider vil vi ikke få en perfekt fordeling iht teoretisk forventning, men resultatet vil være svært nærme og er nærme nok til at vi kan bruke sannsynlighetsfordelingen til å lage forventninger om utfall: 6 000 000 terningkast: ## minterning ## 1 2 3 4 5 6 ## 1000492 998250 1000216 1000832 1001422 998788 Hvis vi setter resultatet fra 6 000 000 terningkast inn i et histogram ser vi at resultatet er svært nærme hva vi teoretisk vil forvente: Figure 4.14: 6 000 000 terningkast 4.3 Poissonfordeling Poissonfordelinger finnes i situasjoner der hendelser skjer vilkårlig i tid (og rom) hvor vi er interessert i kun antallet hendelser i et gitt tidsintervall. Vi kan f.eks. være interessert i hvor mange supporthenvendelser vi får i løpet av en time, antallet feilmedisineringer per uke, hvor mange besøk avdelingen får per dag o.l. Andre eksempler kan være antall trafikkulykker langs en angitt veistrekning, antall elgpåkjørlser på en togstrekning, eller antall av en gitt art fugler i et definert område i et definert tidsrom. En hendelse må være uavhengig tidsmessig av andre hendelser (det er altså ikke økt sannsynlighet for at en hendelse vil skje fordi en tilsvarende hendelse akkurat har skjedd), sannsynligheten for en hendelse i et kort perspektiv er lik sannsynligheten over et lengre perspektiv, og ettersom et tidsintervall blir kortere og kortere vil sannsynligheten for hendelsen gå mot null. Poissonfordeling uttrykker sannsynligheten for at et gitt antall hendelser inntreffer i et gitt tidsintervall (eller et gitt geografisk domene) og at vi kjenner gjennomsnittlig hvor ofte hendelsen inntreffer. Denne sannsynligheten uttrykkes som en lambdaverdi (\\(\\lambda\\)). Eksempelet under er hentet fra Soage (2020): Figure 4.15: Poissonfordelinger Ut fra hvilken \\(\\lambda\\)-verdi vi setter kan vi si noe om sannsynligheten for at et antall hendelser inntreffer. Ugarte, Militino, and Arnholt (2016) eksemplifiserer Poissonfordeling ved å vise til at det i gjennomsnitt skåres 2,5 mål i en VM-kamp i fotball. Denne situasjonen tilfredsstiller forutsetningene for å bruke Possionfordeling.Vi kan grafisk framstille sannsynlighetsfordeingen slik: Figure 4.16: Poissonfordeling mål i VM-kamp fotball I R kan vi også enkelt regne ut den nøyaktige sannsynligheten for x antall mål gitt forutsetningen om at det i snitt skåres 2.5 mål pr kamp til å være 0. Vi kan bruke sannsynlighetsfordelingen til å regne ut sannsynligheten for et gitt antall mål, f.eks.: Sannsynligheten for 0 mål = 0.082085 Sannsynligheten for 1 mål = 0.2052125 Sannsynligheten for 2 mål = 0.2565156 Sannsynligheten for 3 mål = 0.213763 Sannsynligheten for 4 mål = 0.1336019 eller f.eks. sannsynligheten for at det skåres mellom 1 og 3 mål (= 0.6754911). 4.4 Geometrisk fordeling En geometrisk fordeling er en diskret fordeling der man teller antall hendelser/forsøk inntil et gitt resultat forekommer. Resultatet er suksess eller feil, altså hvor mange ganger man har en hendelse før man får en suksess eller feil (avhengig av hva man måler). Et eksempel er hvor mange ganger man må kaste to terninger for å få 11 i sum. Man kaster da to terninger til første gang man får 11 (= suksess). En geometrisk distribusjon kan se slik ut (p = 0,4): Figure 4.17: Geometrisk fordeling I statistisk prosesskontroll er denne typen fordeling til stede når man f.eks. teller antall dager mellom sjeldne hendelser. Man teller antall dager før man f.eks. får et alvorlig avvik på en medisinering, en operasjon e.l. I geometrisk fordeling er sannsynligheten for et gitt utfall uavhengig av om det har skjedd før. Man kan bruke geometrisk fordeling f.eks. til å estimere hvor mange dager man normalt vil forvente det går mellom en sjelden hendelse. Hvis man gjennom erfaringstall vet at sannsynligheten for en sjelden hendelse er p = 0.035 vil man forvente at det går 1/0.035 \\(\\approx\\) 29 dager mellom hver hendelse. Geometrisk distribusjon kan hjelpe oss i en statistisk prosesskontroll for å finne normal/unormal variasjon ved sjeldne hendelser. Det kan være verdt å merke seg at binomial og geometrisk fordeling skiller seg fra hverandre ved at geometrisk fordeling har et ukjent antall hendelser (man fortsetter til man får første suksess/feil), mens binomial fordeling har et gitt antall hendelser. Som vi skal se i senere eksempler derfor geometrisk fordeling viktig når vi håndterer sjeldne hendelser, fordi vi ikke kjenner hvor mange dager det f.eks. går før vi får første suksess/feil. 4.5 Eksponensiell fordeling En tilfeldig kontinuerlig variabel kan sies å være analog til den geometriske distribusjonen, men for kontinuerlige data. Den eksponensielle distribusjonen brukes ofte for å modellere tid mellom to hendelser. I statistisk prosesskontroll vil vi typisk bruke denne distribusjonen hvis vi måler tid mellom to sjeldne hendelser. Hvis vi f.eks. måler tiden mellom uventet dødsfall som følge av en type rutineoperasjon på et sykehus vil den ha en eksponensiell distribusjon hvis sannsynligheten for at hendelsen inntreffer innenfor t gitt tidsintervall er omtrentlig proporsjonal med lengde på tidsintervallet (Taboga 2017). Eksponensielle fordelinger har samme grunnform, men kan ha ulik bratthet avhengig av den såkalte lamdaverdien (= en parameter for raten av hendelser). Lambdaverdi er en parameter for hvor ofte hendelsene forventes å skje. Figure 4.18: Eksponensiell fordeling R-kode for utregning av areal mellom to x-verdier i en normalfordeing (=sannsynlighet for at en gitt x-verdi ligger i intervallet mellom de to x-verdiene): pnorm(2,mean=0,sd=1)-pnorm(-2,mean=0,sd=1) pnorm(3,mean=0,sd=1)-pnorm(-3,mean=0,sd=1) Normalfordelingen er dessuten en god tilnærming til binomialfordeling med høyt antall observasjoner (høy n), og også til poissonfordeling med høy frekvens. Dette forfølger vi imidlertid ikke videre i dette kompendiet. Chebyshevs teorem vil imidlertid gjelde for alle datasett. Teoremet belyses i eget vedlegg for de spesielt interesserte "],["er-dataene-dine-normalfordelte.html", "5 Er dataene dine normalfordelte? 5.1 Q-Q plott 5.2 Anderson-Darling test for normalitet", " 5 Er dataene dine normalfordelte? I forrige kapittel viste vi til at data har ulike fordelinger, og at ulike analyser vi gjør i statistisk prosesskontroll har forutsetninger/bygger på antalkelser om hvordan dataene er fordelt (det gjelder forsåvidt alle statistiske analyser vi gjør). Så i dette kapittelet skal vi se nærmere på hvordan vi kan avgjøre om dataene våre er normalfordelte - i mange tilfeller vil det være hensiktsmessig å først sjekke for normalitet siden veldig mange statistiske analyser forutsetter det.15 Vi skal også være klar over at utregning av såkalte testverdier (som Shapiro-Wilk eller Anderson-Darling) også bygger på visse forutsetninger. Vi har imidlertid en metode som vi kan kalle forutsetningsfri som vi anbefaler å begynne med: Q-Q plott. 5.1 Q-Q plott Både histogrammet og Q-Q plottet er visuelle måter å undersøke om en distribusjon er normalfordelt eller ikke. Selv om de ikke alltid gir et entydig svar er de egnet til å gi oss et inntrykk av om en datadistribusjon er normalfordelt eller ikke. Setter man en normalfordelingskurve på et histogram gir det en indikasjon. Som hjelpemiddel er imidlertid Q-Q plott langt bedre. Q-Q plottet (quantile-quantile plot) kan tolkes ved å se om dataverdiene ligger langs en rett linje med ca 45 graders vinkel. Q-Q plottet (se video for forklaring på utregning) innebærer å se to distribusjoner mot hverandre  empirisk fordeling (dataene) og teoretisk forventning ut fra en fordelingsmodell (som normalfordeling om vi snakker om \"normal Q-Q plott - dvs vi ser om vår empiriske datafordeling og normalfordelingen er lik). Om de samsvarer perfekt ligger de på en helt rett linje (x = y). I eksempelet under vil da alle punktene ligge perfekt oppå den rette linjen. Siden vi vet den teoretiske distribusjonen til normalfordelingen, kan vi bruke denne teoretiske fordelingen til å plotte den mot datasettet vi sitter med. Vi har laget en video som viser hvordan du kan lage et Q-Q plott fra scratch i Excel. Statistikkprogrammer (som R og evt statistikk/SPC plug-ins i Excel) lager naturligvis dette (og regner ut testverdier) svært raskt og enkelt for oss. La oss først se på et Q-Q plott som viser en normalfordeling (du kan laste ned Excelfila hvis du ønsker dataene): Download QQ_norm.xlsx Figure 5.1: Q-Q plott normalfordeling Vi ser at dette Q-Q plottet viser oss at vi kan være ganske sikre på at dette datasettet er normalfordelt (noe som gir meninig siden vi har brukt R til å lage et normalfordelt datasett). Tolkning av Q-Q plott er imidlertid ikke alltid så enkelt som i eksempelet ovenfor - det er en viss grad av subjektivitet involvert. Underhar vi gjengitt noen typiske mønstre vi kan se og hva de skyldes. Som et supplement til Q-Q plott kan vi bruke ulike testverdier (fra f.eks. Shapiro-Wilk og Anderson-Darling). Disse kommer vi tilbake til senere i kapittelet. I det første eksempelet på avvik fra den helt klare normalfordelingen lager vi et datasett som har en skjevhet mot høyre (right skewness) - også kalt positiv skjevhet (uten at det legges noe positivt i positivt). Datasettet kan lastes ned i Excelformat her: Download QQ_norm_rs.xlsx Figure 5.2: Q-Q plott - fordeling skjevhet høyre I et datasett med høyreskjevhet vil ofte Q-Q plottet vise en bananform med bunnen/midten av bananen ned mot høyre hjørne og endene pekende oppover/utover fra den rette linjen. I det neste datasettet har vi generert en kraftig skjevhet til venstre. Q-Q plottet får da en omvendt bananform i forhold til høyre skjevhet, altså en topp på midten og to ender som svinger nedover ift den rette linja. Datasettet finner du her: Download QQ_norm_ls.xlsx Figure 5.3: Q-Q plott - fordeling skjevhet venstre De neste to tilfellene av avvik vi skal ta for oss er såkalte light-tailed (lette haler med liten sannsynlighet for ekstreme verdier og utvalg tendeerer til å ikke fravike gjennomsnittet med mye) og heavy-tailed (fete/tunge haler med større sannsynlighet for at ekstreme verdier vil forekomme) fordelinger. Datasett for fete haler er her: Download QQ_ht.xlsx Figure 5.4: Q-Q plott - heavy-tail Fordelinger med tunge haler vil ofte følge en slags omvendt S-form. Den starter med å vokse raskere enn normalfordelingen og ender med å vokse saktere. Datasettet for lette haler finner du her: Download QQ_lt.xlsx Figure 5.5: Q-Q plott - light-tail Q-Q plottet for en fordeling med lette haler har ofte en S-form. Dataene vokser saktere enn normalfordelingen i starten før den følger vekstraten til normalfordelingen. Mot slutten vokser den raskere enn normalfordelingen. Derfor bøyer den av fra normalfordelingen. Til slutt kan vi se på en typisk bimodial fordeling, med datasett her: Download QQ_bimod.xlsx pacman::p_load(gridExtra, writexl, ggplot2, tidyverse) set.seed(10) mode1 &lt;- rnorm(50,2,1) mode1 &lt;- mode1[mode1 &gt; 0] mode2 &lt;- rnorm(50,6,1) mode2 &lt;- mode2[mode2 &gt; 0] qqbimod &lt;- as_tibble(sort(c(mode1,mode2))) # Eksportere datasettet write_xlsx(qqbimod,&quot;QQ_bimod.xlsx&quot;) # Plotte histogram og Q-Q plott qqbimodhist &lt;- ggplot(qqbimod, aes(x=value)) + geom_histogram(color=&quot;black&quot;, fill=&quot;lightblue&quot;) qqbimod_plott &lt;- ggplot(qqbimod, aes(sample = value)) + stat_qq() + stat_qq_line() + ggtitle(&quot; Normal Q-Q plott - bimodial&quot;) + labs(x = &quot;Teoretisk forventning&quot;, y = &quot;Data&quot;) grid.arrange(qqbimodhist, qqbimod_plott, ncol=2) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. Den bimodiale fordelingen viser ofte et brudd eller et distinkt knekkpunkt rundt krysning av den rette linja, med en del av linja på hver side av den rette linja. Vi har nå sett på noen typiske eksempler på mønstre i Q-Q plott. Det kan imidlertid være vanskelig å bedømme fordelinger som ligger nære normalfordelingen, men likevel ikke perfekt oppå (du vil trolig aldri se en perfekt match med mindre du har generert et normalfordelt datasett med mange datapunkter). Vi kan supplere Q-Q plottene med visse statistiske tester - det er tema for de neste delkapitlene (men husk: disse statistiske testene har sine egne forutsetninger og er heller ikke uten utfordringer). 5.2 Anderson-Darling test for normalitet Det er tildels stor uenighet om hvor alvorlig avvik fra normalfordelingens teoretiske forventning man kan være for likevel å bruke ulike statistiske analyser. Mange analyser er ganske robuste for avvik. Det beste rådet tror vi er å være bevisst på dette og sjekke med statistikkbøker og artikler hvor robuste de enkelte analysene er for avvik "],["referanser.html", "Referanser", " Referanser "],["vedlegg-1---r-kode.html", "Vedlegg 1 - R kode", " Vedlegg 1 - R kode Kapittel 2 Sette opp nødvendige pakker: pacman::p_load(ggplot2, readxl, tidyverse, ggpubr, dplyr, hrbrthemes) Lage fig 2.1: prepost_eksempel_long &lt;- as_tibble(read_excel(&quot;prepost_eksempel_long.xlsx&quot;)) ggbarplot(prepost_eksempel_long, x = &quot;Periode&quot;, y = &quot;Verdi&quot;, add = c(&quot;mean&quot;), color = &quot;blue&quot;, fill = &quot;lightblue&quot;) Lage fig 2.2: ggline(prepost_eksempel_long, x = &quot;Periode&quot;, y = &quot;Verdi&quot;, add = c(&quot;mean_se&quot;, &quot;jitter&quot;)) Lage fig 2.3: t &lt;- 1:24 z &lt;- c(prepost_eksempel_long$Verdi) plot(t,z, type=&quot;l&quot;, col=&quot;blue&quot;, lwd=3, xlab=&quot;Periode&quot;, ylab=&quot;Antall&quot;, xaxt=&quot;n&quot;) axis(1, seq(0,24,2)) abline(v=12, col=&quot;red&quot;, lwd = 3) text(15.5, 40, &quot;Endring i prosedyre&quot;, col = &quot;red&quot;) Kapittel 3 Lage fig 3.1: # Genererer tilfeldig tall for regel 1: pacman::p_load(xlsx, ggplot2, tidyverse, ggpubr) set.seed(91) regel1_x &lt;- as_tibble(rnorm(100, mean = 0, sd = 1)) %&gt;% rename(x = value) %&gt;% add_column(nr = 1:100) %&gt;% relocate(nr) regel1_y &lt;- as_tibble(rnorm(100, mean = 0, sd = 1)) %&gt;% rename(y = value) %&gt;% add_column(nr = 1:100) %&gt;% relocate(nr) regel1 &lt;- merge(regel1_x,regel1_y,by=&quot;nr&quot;) regel1_plot &lt;- ggplot(regel1, aes(x = x, y = y)) + geom_point(size = 1) + labs(x = &quot;x&quot;, y = &quot;y&quot;, title = &quot;Regel 1&quot;) + xlim(-5,5) + ylim(-5,5)+ geom_vline(xintercept = 0, col = &quot;red&quot;) + geom_hline(yintercept = 0, col = &quot;red&quot;) # Genererer tilfeldig tall for regel 2: set.seed(92) regel2_x &lt;- as_tibble(rnorm(100, mean = 0, sd = 2)) %&gt;% rename(x = value) %&gt;% add_column(nr = 1:100) %&gt;% relocate(nr) ## Setter sd = 2 fordi variasjonen med regel 2 er dobbel av regel 1 (jfr SPC for Excel) regel2_y &lt;- as_tibble(rnorm(100, mean = 0, sd = 2)) %&gt;% rename(y = value) %&gt;% add_column(nr = 1:100) %&gt;% relocate(nr) regel2 &lt;- merge(regel2_x,regel2_y,by=&quot;nr&quot;) regel2_plot &lt;- ggplot(regel2, aes(x = x, y = y)) + geom_point(size = 1) + labs(x = &quot;x&quot;, y = &quot;y&quot;, title = &quot;Regel 2&quot;) + xlim(-5,5) + ylim(-5,5) + geom_vline(xintercept = 0, col = &quot;red&quot;) + geom_hline(yintercept = 0, col = &quot;red&quot;) # Henter tall fra Excel for regel 3: regel3 &lt;- read.xlsx(&quot;Funnel_blankedata_regel3.xlsx&quot;, 1) regel3_plot &lt;- ggplot(regel3, aes(x = Regel_3_x, y = Regel_3_y)) + geom_point(size = 1) + labs(x = &quot;x&quot;, y = &quot;y&quot;, title = &quot;Regel 3&quot;) + xlim(-5,5) + ylim(-5,5)+ geom_vline(xintercept = 0, col = &quot;red&quot;) + geom_hline(yintercept = 0, col = &quot;red&quot;) # Henter tall fra Excel for regel 4: regel4 &lt;- read.xlsx(&quot;Funnel_blankedata_regel4.xlsx&quot;, 1) regel4_plot &lt;- ggplot(regel4, aes(x = Regel_4_x, y = Regel_4_y)) + geom_point(size = 1) + labs(x = &quot;x&quot;, y = &quot;y&quot;, title = &quot;Regel 4&quot;) + xlim(-5,5) + ylim(-5,5)+ geom_vline(xintercept = 0, col = &quot;red&quot;) + geom_hline(yintercept = 0, col = &quot;red&quot;) # Setter plottene sammen: ggarrange(regel1_plot, regel2_plot, regel3_plot, regel4_plot + rremove(&quot;x.text&quot;), ncol = 2, nrow = 2) Lage fig 3.2: regel3_2 &lt;- read.xlsx(&quot;Funnel_blankedata_regel3_2.xlsx&quot;, 1) regel3_2_plot &lt;- ggplot(regel3_2, aes(x = x, y = y)) + geom_point(size = 1) + labs(x = &quot;x&quot;, y = &quot;y&quot;, title = &quot;Regel 3 - annet førstetreff&quot;) + xlim(-5,5) + ylim(-5,5)+ geom_vline(xintercept = 0, col = &quot;red&quot;) + geom_hline(yintercept = 0, col = &quot;red&quot;) regel3_2_plot Lage fig 3.3: regel4_2 &lt;- read.xlsx(&quot;Funnel_blankedata_regel4_2.xlsx&quot;, 1) regel4_2_plot &lt;- ggplot(regel4_2, aes(x = x, y = y)) + geom_point(size = 1) + labs(x = &quot;x&quot;, y = &quot;y&quot;, title = &quot;Regel 4 - annet førstetreff&quot;) + xlim(-2,10) + ylim(-10,2)+ geom_vline(xintercept = 0, col = &quot;red&quot;) + geom_hline(yintercept = 0, col = &quot;red&quot;) regel4_2_plot Lage fig 3.4: pacman::p_load(qicharts2) regel1x &lt;- regel1 %&gt;% pull(2) regel1y &lt;- regel1 %&gt;% pull(3) regel1xrun &lt;- qic(regel1x, title = &#39;x-verdi ved regel 1&#39;, ylab = &quot;verdi&quot;, xlab = &quot;Forsøk nr.&quot;) regel1yrun &lt;- qic(regel1y, title = &#39;y-verdi ved regel 1&#39;, ylab = &quot;verdi&quot;, xlab = &quot;Forsøk nr.&quot;) ggarrange(regel1xrun, regel1yrun + rremove(&quot;x.text&quot;), ncol = 2, nrow = 1, widths = c(1, 1)) Lage fig 3.5: pacman::p_load(qicharts2) regel2x &lt;- regel2 %&gt;% pull(2) regel2y &lt;- regel2 %&gt;% pull(3) regel2xrun &lt;- qic(regel2x, title = &#39;x-verdi ved regel 2&#39;, ylab = &quot;verdi&quot;, xlab = &quot;Forsøk nr.&quot;) regel2yrun &lt;- qic(regel2y, title = &#39;y-verdi ved regel 2&#39;, ylab = &quot;verdi&quot;, xlab = &quot;Forsøk nr.&quot;) ggarrange(regel2xrun, regel2yrun + rremove(&quot;x.text&quot;), ncol = 2, nrow = 1, widths = c(1, 1)) Lage fig 3.6: pacman::p_load(qicharts2) regel3x &lt;- regel3 %&gt;% pull(2) regel3y &lt;- regel3 %&gt;% pull(3) regel3xrun &lt;- qic(regel3x, title = &#39;x-verdi ved regel 3&#39;, ylab = &quot;verdi&quot;, xlab = &quot;Forsøk nr.&quot;) regel3yrun &lt;- qic(regel3y, title = &#39;y-verdi ved regel 3&#39;, ylab = &quot;verdi&quot;, xlab = &quot;Forsøk nr.&quot;) ggarrange(regel3xrun, regel3yrun + rremove(&quot;x.text&quot;), ncol = 2, nrow = 1, widths = c(1, 1)) Lage fig 3.7: pacman::p_load(qicharts2) regel4x &lt;- regel4 %&gt;% pull(2) regel4y &lt;- regel4 %&gt;% pull(3) regel4xrun &lt;- qic(regel4x, title = &#39;x-verdi ved regel 4&#39;, ylab = &quot;verdi&quot;, xlab = &quot;Forsøk nr.&quot;) regel4yrun &lt;- qic(regel4y, title = &#39;y-verdi ved regel 4&#39;, ylab = &quot;verdi&quot;, xlab = &quot;Forsøk nr.&quot;) ggarrange(regel4xrun, regel4yrun + rremove(&quot;x.text&quot;), ncol = 2, nrow = 1, widths = c(2, 2)) Lage fig 3.8: pacman::p_load(xlsx, qicharts2, tidyverse, ggplot2, ggpubr) toteam1 &lt;- read.xlsx(&quot;toteam.xlsx&quot;, 1) team1 &lt;- qic(Team.1, data = toteam1, chart = &#39;i&#39;, show.grid = TRUE, title = &quot;Team 1&quot;, ylab = &quot;Antall defekter pr uke&quot;, xlab = &quot;Uke #&quot;) team2 &lt;- qic(Team.2, data = toteam1, chart = &#39;i&#39;, show.grid = TRUE, title = &quot;Team 2&quot;, ylab = &quot;Antall defekter pr uke&quot;, xlab = &quot;Uke #&quot;) ggarrange(team1, team2 + rremove(&quot;x.text&quot;), ncol = 2, nrow = 1, widths = c(1, 1)) Lage fig 3.9: pacman::p_load(xlsx, qicharts2, tidyverse, ggplot2, ggpubr) toteam2 &lt;- readxl::read_excel(&quot;toteam.xlsx&quot;) %&gt;% pivot_longer(c(&quot;Team 1&quot;, &quot;Team 2&quot;)) qic(Nr, value, data = toteam2, facets = ~name, xlab = &quot;Uke #&quot;, ylab = &quot;Antall defekter pr uke&quot;, title = &quot;To team - like prosesser - ulik variasjon&quot;) Kapittel 4 Lage fig 4.1: pacman::p_load(tidyverse) set.seed(30) x = rnorm(100, 179, 16) hist(x, xlab = &quot;Høyde&quot;, ylab = &quot;Antall&quot;, main = &quot;Histogram for genererte høydedata&quot;) Lage fig 4.2: data1 &lt;- sample(165:175, 50, replace=TRUE) data2 &lt;- sample(170:180, 30, replace=TRUE) data3 &lt;- sample(180:185, 15, replace = TRUE) data4 &lt;- sample(185:190, 5, replace = TRUE) data &lt;- c(data1, data2, data3, data4) hist(data, xlab = &quot;Høyde&quot;, ylab = &quot;Antall&quot;, main = &quot;Histogram for genererte høydedata&quot;) Lage fig 4.3: pacman::p_load(ggplot2, readxl, tidyverse, ggfortify) set.seed(100) normalfordeling &lt;- rnorm(100, mean = 0, sd = 1) hist(normalfordeling, main = &quot;Genererte, normalfordelte data&quot;, xlab = &quot;x&quot;, ylab = &quot;f(x)&quot;, border = &quot;black&quot;, col = &quot;gray&quot;, xlim = c(-4,4), ylim = c(0,0.5), las = 1, probability = TRUE) Lage fig 4.4: set.seed(100) normalfordeling &lt;- rnorm(100, mean = 0, sd = 1) hist(normalfordeling, main = &quot;Genererte, normalfordelte data&quot;, xlab = &quot;x&quot;, ylab = &quot;f(x)&quot;, border = &quot;black&quot;, col = &quot;gray&quot;, xlim = c(-4,4), ylim = c(0,0.5), las = 1, probability = TRUE) m &lt;- mean(normalfordeling) std &lt;- sqrt(var(normalfordeling)) curve(dnorm(x, mean = m, sd = std), col=&quot;darkblue&quot;, lwd = 3, add = TRUE, yaxt = &quot;n&quot;) Lage fig 4.5: pacman::p_load(ggplot2, readxl, tidyverse, ggfortify) ggplot(data.frame(x = c(-4, 4)), aes(x)) + geom_function(fun = dnorm, colour = &quot;darkblue&quot;, size = 1.5) + theme_classic() + scale_y_continuous(limits = c(0, 0.5), breaks = seq(0, 0.5, by = 0.1)) Lage fig 4.6: x &lt;- seq(-4, 4, length=200) y &lt;- dnorm(x) plot(x, y, type=&quot;l&quot;, lty=1, lwd = 2, col = &quot;red&quot;, xlab=&quot;x&quot;, ylab=&quot;f(x)&quot;) x &lt;- seq(-1,1,length=100) y &lt;- dnorm(x) polygon(c(-1,x,1),c(0,y,0),col=&quot;lightblue&quot;) abline(v=-1, col=&quot;green&quot;, lwd = 2) text(1.3, 0.38, &quot;1 SD&quot;, col = &quot;black&quot;) text(-1.35, 0.38, &quot;-1 SD&quot;, col = &quot;black&quot;) abline(v=1, col=&quot;green&quot;, lwd = 2) text(0, 0.2, &quot;68 %&quot;, col = &quot;black&quot;) Lage fig 4.7: x &lt;- seq(-4,4,length=200) y &lt;- dnorm(x) plot(x, y, type=&quot;l&quot;, lty=1, lwd = 2, col = &quot;red&quot;, xlab=&quot;x&quot;, ylab=&quot;f(x)&quot;) x &lt;- seq(-2,2,length=200) y &lt;- dnorm(x) polygon(c(-2,x,2),c(0,y,0),col=&quot;lightblue&quot;) abline(v=-2, col=&quot;green&quot;, lwd = 2) text(2.3, 0.38, &quot;2 SD&quot;, col = &quot;black&quot;) text(-2.35, 0.38, &quot;-2 SD&quot;, col = &quot;black&quot;) abline(v=2, col=&quot;green&quot;, lwd = 2) text(0, 0.2, &quot;95 %&quot;, col = &quot;black&quot;) Utregning av areal mellom to x-verdier i normalfordeling: pnorm(2,mean=0,sd=1)-pnorm(-2,mean=0,sd=1) Lage fig 4.8: x &lt;- seq(-4,4,length=200) y &lt;- dnorm(x) plot(x,y,type=&quot;l&quot;,lwd=2,col=&quot;red&quot;, xlab=&quot;x&quot;, ylab=&quot;f(x)&quot;) x &lt;- seq(-3,3,length=200) y &lt;- dnorm(x) polygon(c(-3,x,3),c(0,y,0),col=&quot;lightblue&quot;) abline(v=-3, col=&quot;green&quot;, lwd = 2) text(3.3, 0.38, &quot;3 SD&quot;, col = &quot;black&quot;) text(-3.35, 0.38, &quot;-3 SD&quot;, col = &quot;black&quot;) abline(v=3, col=&quot;green&quot;, lwd = 2) text(0, 0.2, &quot;99.7 %&quot;, col = &quot;black&quot;) Lage fig 4.9: y.norm &lt;- rnorm(n= 100000, mean = 0, sd = 1) h &lt;- hist(y.norm, breaks = 100, plot = F) cuts &lt;- cut(h$breaks, c(-Inf,-3,-2,-1,1,2,3,Inf), right = F) # right=False; sets intervals to be open on the right closed on the left plot(h, col = rep(c(&quot;white&quot;, &quot;4&quot;,&quot;3&quot;,&quot;2&quot;,&quot;3&quot;,&quot;4&quot;, &quot;white&quot;))[cuts], main = &#39;Normalfordeling&#39;, xlab = &#39;&#39;, freq = F, ylim = c(0,0.6)) lwd = 3 # horzintal lines lines(x = c(2,-2), y = c(0.48,0.48), type = &quot;l&quot;, col=3, lwd = lwd) lines(x = c(3,-3), y = c(0.55,0.55), type = &quot;l&quot;, col=4, lwd = lwd) lines(x = c(1,-1), y = c(0.41,0.41), type = &quot;l&quot;, col=2, lwd = lwd) # vertical lines lines(x = c(1,1), y = c(0,0.41), type = &quot;l&quot;, col=2, lwd = lwd) lines(x = c(-1,-1), y = c(0,0.41), type = &quot;l&quot;, col=2, lwd = lwd) lines(x = c(2,2), y = c(0,0.48), type = &quot;l&quot;, col=3, lwd = lwd) lines(x = c(-2,-2), y = c(0,0.48), type = &quot;l&quot;, col=3, lwd = lwd) lines(x = c(3,3), y = c(0,0.55), type = &quot;l&quot;, col=4, lwd = lwd) lines(x = c(-3,-3), y = c(0,0.55), type = &quot;l&quot;, col=4, lwd = lwd) # text text(0, 0.44, &quot;68%&quot;, cex = 1.5, col=2) text(0, 0.51, &quot;95%&quot;, cex = 1.5, col=3) text(0, 0.58, &quot;99.7%&quot;, cex = 1.5, col=4) Lage fig 4.10: success &lt;- 0:20 plot(success,dbinom(success,size=20,prob=.5), type=&#39;h&#39;, main=&quot;Binomial distribusjon (n=20, p=0.5)&quot;, ylab=&quot;Sannsynlighet&quot;, xlab = &quot;Suksess&quot;, lwd=10) Lage fig 4.11: success &lt;- 0:20 plot(success,dbinom(success,size=20,prob=.2), type=&#39;h&#39;, main=&quot;Binomial distribusjon (n=20, p=0.2)&quot;, ylab=&quot;Sannsynlighet&quot;, xlab = &quot;Suksess&quot;, lwd=10) Lage fig 4.12: set.seed(32) terning10 &lt;- sample(1:6, 10, replace = TRUE) stripchart(terning10, method = &quot;stack&quot;, offset = .5, at = 0, pch = 19, col = &quot;steelblue&quot;, main = &quot;10 terningkast&quot;, xlab = &quot;Verdi på terning&quot;, ylab = &quot;Antall&quot;)) Lage fig 4.13: set.seed(33) terning10 &lt;- sample(1:6, 100, replace = TRUE) stripchart(terning10, method = &quot;stack&quot;, offset = .5, at = 0, pch = 19, col = &quot;steelblue&quot;, main = &quot;100 terningkast&quot;, xlab = &quot;Verdi på terning&quot;, ylab = &quot;Antall&quot;) Lage simulering av terningkast: set.seed(43) terning_runde1 &lt;- sample(1:6, 600, replace = TRUE) table(terning_runde1) set.seed(44) terning_runde2 &lt;- sample(1:6, 600, replace = TRUE) table(terning_runde2) set.seed(45) terning_runde3 &lt;- sample(1:6, 600, replace = TRUE) table(terning_runde3) Lage fig 4.14: set.seed(46) minterning &lt;- sample(1:6, 6000000, replace = TRUE) options(scipen=999) hist(minterning, main=&quot;Histogram for 6 000 000 terningkast&quot;, ylab=&quot;Antall&quot;, xlab = &quot;Verdi på terning&quot;) Lage fig 4.15: # Grid of X-axis values x &lt;- 0:50 #----------- # lambda: 5 #----------- lambda &lt;- 5 plot(dpois(x, lambda), type = &quot;h&quot;, lwd = 2, main = &quot;Poisson sannsynlighetsfordeling&quot;, ylab = &quot;P(X = x)&quot;, xlab = &quot;Antall hendelser&quot;) #----------- # lambda: 10 #----------- lambda &lt;- 10 lines(dpois(x, lambda), type = &quot;h&quot;, lwd = 2, col = rgb(1,0,0, 0.7)) #----------- # lambda: 20 #----------- lambda &lt;- 20 lines(dpois(x, lambda), type = &quot;h&quot;, lwd = 2, col = rgb(0, 1, 0, 0.7)) # Legend legend(&quot;topright&quot;, legend = c(&quot;5&quot;, &quot;10&quot;, &quot;20&quot;), title = expression(lambda), title.adj = 0.75, lty = 1, col = 1:3, lwd = 2, box.lty = 0) Lage fig 4.16: maal &lt;- 0:10 plot(maal, dpois(maal, lambda=2.5), type=&#39;h&#39;, main=&#39;Poissonfordeling (lambda = 2.5)&#39;, ylab=&#39;Sannsynlighet&#39;, xlab =&#39;# Mål&#39;, lwd=3) Regne ut sannsynligheter: # Sannsynligheten for 0 mål dpois(x = 0, lambda = 2.5) # Sannsynligheten for 1 mål dpois(x = 1, lambda = 2.5) # Sannsynligheten for 2 mål dpois(x = 2, lambda = 2.5) # Sannsynligheten for 3 mål dpois(x = 3, lambda = 2.5) # Sannsynligheten for 4 mål dpois(x = 4, lambda = 2.5) # sannsynligheten for mellom 1 og 3 mål: dpois(x = 1, lambda = 2.5) + dpois(x=2, lambda = 2.5) + dpois(x=3, lambda = 2.5) Lage fig 4.17: x_dgeom &lt;- seq(1, 20, by = 1) y_dgeom &lt;- dgeom(x_dgeom, prob = 0.4) plot(y_dgeom, type=&quot;l&quot;, main=&quot;Geometrisk fordeling for p = 0.4&quot;, ylab=&quot;f(x)&quot;, xlab = &quot;x&quot;) Lage fig 4.18: pacman::p_load(ggpubr) eksford &lt;- seq(0, 20, length.out=1000) dat1 &lt;- data.frame(x=eksford, fx=dexp(eksford, rate=0.2)) %&gt;% add_column(ID = 1:1000) %&gt;% relocate(3) dat2 &lt;- data.frame(x=eksford, fx=dexp(eksford, rate=1)) %&gt;% add_column(ID = 1:1000) %&gt;% relocate(3) dat3 &lt;- data.frame(x=eksford, fx=dexp(eksford, rate=1.5)) %&gt;% add_column(ID = 1:1000) %&gt;% relocate(3) dat4 &lt;- data.frame(x=eksford, fx=dexp(eksford, rate=2)) %&gt;% add_column(ID = 1:1000) %&gt;% relocate(3) dat1plot &lt;- ggplot(dat1, aes(x=x, y=fx)) + geom_line() + ggtitle(expression( ~ lambda ~ &quot; = 0.2&quot;)) dat2plot &lt;- ggplot(dat2, aes(x=x, y=fx)) + geom_line() + ggtitle(expression( ~ lambda ~ &quot; = 1.0&quot;)) dat3plot &lt;- ggplot(dat3, aes(x=x, y=fx)) + geom_line() + ggtitle(expression( ~ lambda ~ &quot; = 1.5&quot;)) dat4plot &lt;- ggplot(dat4, aes(x=x, y=fx)) + geom_line() + ggtitle(expression( ~ lambda ~ &quot; = 2.0&quot;)) ggarrange(dat1plot, dat2plot, dat3plot, dat4plot + rremove(&quot;x.text&quot;), ncol = 2, nrow = 2, widths = c(1, 1)) Kapittel 5 Lage fig 5.1: pacman::p_load(tidyverse, ggplot2, writexl) # Lage normalfordelt datasett set.seed(89) qqnorm &lt;- rnorm(10000, mean=90, sd=5) qqnorm &lt;- as_tibble(qqnorm) # Plotte Q-Q plott qqnorm_plott &lt;- ggplot(qqnorm, aes(sample = value)) + stat_qq() + stat_qq_line() print(qqnorm_plott + ggtitle(&quot;Normal Q-Q plott&quot;) + labs(x = &quot;Teoretisk forventning&quot;, y = &quot;Data&quot;)) Lage fig 5.2: # Lage datasett med right skew N &lt;- 5000 qqrightskew &lt;- rnbinom(N, 10, .1) qqrightskew &lt;- as_tibble(qqrightskew) # Plotte histogram og Q-Q plott qqrighthist &lt;- ggplot(qqrightskew, aes(x=value)) + geom_histogram(color=&quot;black&quot;, fill=&quot;lightblue&quot;) qqrightskew_plott &lt;- ggplot(qqrightskew, aes(sample = value)) + stat_qq() + stat_qq_line() + ggtitle(&quot;Normal Q-Q plott - skjevhet høyre&quot;) + labs(x = &quot;Teoretisk forventning&quot;, y = &quot;Data&quot;) grid.arrange(qqrighthist, qqrightskew_plott, ncol=2) Lage fig 5.3: pacman::p_load(gridExtra, writexl, ggplot2, tidyverse) # Lage datasett med left skew set.seed(91) N=5000 qqleftskew &lt;- rbeta(N,2,0.5,ncp=2) qqleftskew &lt;- as_tibble(qqleftskew) # Plotte histogram og Q-Q plott&quot; qqlefthist &lt;- ggplot(qqleftskew, aes(x=value)) + geom_histogram(color=&quot;black&quot;, fill=&quot;lightblue&quot;) qqleftskew_plott &lt;- ggplot(qqleftskew, aes(sample = value)) + stat_qq() + stat_qq_line() + ggtitle(&quot;Normal Q-Q plott - skjevhet venstre&quot;) + labs(x = &quot;Teoretisk forventning&quot;, y = &quot;Data&quot;) grid.arrange(qqlefthist, qqleftskew_plott, ncol=2) Lage fig 5.4: pacman::p_load(gridExtra, writexl, ggplot2, tidyverse, LambertW) # Lage datasett med fet hale set.seed(92) qqflat &lt;- rLambertW(n=100, distname = &quot;normal&quot;, beta = c(0,1), delta = 0.5) qqflat &lt;- as_tibble(qqflat) # Plotte histogram og Q-Q plott qqflathist &lt;- ggplot(qqflat, aes(x=value)) + geom_histogram(color=&quot;black&quot;, fill=&quot;lightblue&quot;) qqflat_plott &lt;- ggplot(qqflat, aes(sample = value)) + stat_qq() + stat_qq_line() + ggtitle(&quot;Q-Q plott - heavy-tail&quot;) + labs(x = &quot;Teoretisk forventning&quot;, y = &quot;Data&quot;) grid.arrange(qqflathist, qqflat_plott, ncol=2) Lage fig 5.5: pacman::p_load(gridExtra, writexl, ggplot2, tidyverse) # Lage datasett med tynn hale set.seed(81) qqlt &lt;- runif(n = 1000, min = -1, max = 1) qqlt &lt;- as_tibble(qqlt) # Plotte histogram og Q-Q plott qqlthist &lt;- ggplot(qqlt, aes(x=value)) + geom_histogram(color=&quot;black&quot;, fill=&quot;lightblue&quot;) qqlt_plott &lt;- ggplot(qqlt, aes(sample = value)) + stat_qq() + stat_qq_line() + ggtitle(&quot; Normal Q-Q plott - light-tail&quot;) + labs(x = &quot;Teoretisk forventning&quot;, y = &quot;Data&quot;) grid.arrange(qqlthist, qqlt_plott, ncol=2) Lage fig 5.6: pacman::p_load(gridExtra, writexl, ggplot2, tidyverse) # Lage bimodialt datasett set.seed(10) mode1 &lt;- rnorm(50,2,1) mode1 &lt;- mode1[mode1 &gt; 0] mode2 &lt;- rnorm(50,6,1) mode2 &lt;- mode2[mode2 &gt; 0] qqbimod &lt;- as_tibble(sort(c(mode1,mode2))) # Plotte histogram og Q-Q plott qqbimodhist &lt;- ggplot(qqbimod, aes(x=value)) + geom_histogram(color=&quot;black&quot;, fill=&quot;lightblue&quot;) qqbimod_plott &lt;- ggplot(qqbimod, aes(sample = value)) + stat_qq() + stat_qq_line() + ggtitle(&quot; Normal Q-Q plott - bimodial&quot;) + labs(x = &quot;Teoretisk forventning&quot;, y = &quot;Data&quot;) grid.arrange(qqbimodhist, qqbimod_plott, ncol=2) Vedlegg 2 pacman::p_load(kableExtra) n &lt;- 10:100 hendelser &lt;- data.frame( &quot;Antall observasjoner&quot; = n, &quot;Øvre grense for serie&quot; = round(log2(n) + 3), &quot;Nedre grense for antall krysninger&quot; = qbinom(0.05, n - 1, 0.5), check.names = FALSE) kbl(hendelser, booktabs = T, longtable = T, caption = &quot;Kritiske verdier&quot;, align = &#39;c&#39;) %&gt;% kable_styling(latex_options = &quot;striped&quot;) %&gt;% kable_styling(latex_options = &quot;repeat_header&quot;) %&gt;% row_spec(0, bold = T) Vedlegg 3 Lage generisk grafisk framstilling av Chebyshevs teorem pacman::p_load(tidyverse) # For å lage eksempelet lager vi to normalfordelte datasett med ulik gjennomsnitt og standardavvik som vi slår sammen set.seed(10) mode1 &lt;- rnorm(1000,2,1) mode1 &lt;- mode1[mode1 &gt; 0] mode2 &lt;- rnorm(1000,6,2) mode2 &lt;- mode2[mode2 &gt; 0] modex2 &lt;- as_tibble(sort(c(mode1,mode2))) # Deretter setter vi dataene inn i et diagram ggplot(modex2, aes(x=value)) + geom_density() + ggtitle(&quot;Eksempel: Bimodal distribusjon&quot;, subtitle = &quot;Eksemplet er kun illustrativt, ikke nøyaktig eller basert på reelle data&quot;) + labs(x = &quot;&quot;, y = &quot;&quot;) + theme_classic() + theme(legend.position = &quot;none&quot;) + scale_x_discrete(labels = NULL, breaks = NULL) + labs(x = &quot;&quot;) + xlim(-0.02, 8) + ylim(-0.02,0.3) + annotate(&quot;segment&quot;, x = 4, y = 0, xend = 4, yend = 0.15, linetype = &quot;dashed&quot;, color = &quot;red&quot;) + annotate(&#39;text&#39;, x = 4, y = -0.015, label = &quot;bar(x)&quot;, parse = TRUE, size = 5) + annotate(&quot;segment&quot;, x = 7.8, y = 0, xend = 7.8, yend = 0.275, color = &quot;darkgreen&quot;) + annotate(&#39;text&#39;, x = 7.8, y = -0.015, label = &quot;bar(x) ~ + ~ 3 ~ sd&quot;, parse = TRUE, size = 5) + annotate(&quot;segment&quot;, x = 0.2, y = 0, xend = 0.2, yend = 0.275, color = &quot;darkgreen&quot;) + annotate(&#39;text&#39;, x = 0.3, y = -0.015, label = &quot;bar(x)~-~3~sd&quot;, parse = TRUE, size = 5) + annotate(&quot;segment&quot;, x = 2.1, y = 0, xend = 2.1, yend = 0.235, color = &quot;blue&quot;) + annotate(&#39;text&#39;, x = 2.1, y = -0.015, label = &quot;bar(x)~-~2~sd&quot;, parse = TRUE, size = 5) + annotate(&quot;segment&quot;, x = 5.9, y = 0, xend = 5.9, yend = 0.235, color = &quot;blue&quot;) + annotate(&#39;text&#39;, x = 5.9, y = -0.015, label = &quot;bar(x)~+~2~sd&quot;, parse = TRUE, size = 5) + annotate(&quot;text&quot;, x=4, y=0.23, label=&quot;Minst 75 %&quot;, color = &quot;blue&quot;) + annotate(&quot;segment&quot;, x = 3.35, y = 0.23, xend = 2.25, yend = 0.23, color = &quot;blue&quot;) + annotate(&quot;segment&quot;, x = 4.6, y = 0.23, xend = 5.8, yend = 0.23, color = &quot;blue&quot;) + annotate(&quot;text&quot;, x=4, y=0.27, label=&quot;Minst 88.89 %&quot;, color = &quot;darkgreen&quot;) + annotate(&quot;segment&quot;,x = 0.3, y = 0.27, xend = 3.2, yend = 0.27, color = &quot;darkgreen&quot;) + annotate(&quot;segment&quot;, x = 4.8, y = 0.27, xend = 7.7, yend = 0.27, color = &quot;darkgreen&quot;) Lage tabell over k og prosent pacman::p_load(tidyverse, kableExtra, knitr) k &lt;- seq(1,4,by = 0.1) auc &lt;- 1-(1/k^2) auc.percent &lt;- round(auc*100) cheb_table &lt;- as_tibble(cbind(k,auc.percent)) kbl(cheb_table) %&gt;% kable_styling(bootstrap_options = &quot;striped&quot;, full_width = F) %&gt;% kable_paper() %&gt;% scroll_box(height = &quot;200px&quot;) Lage graf over k og prosent plot(k, auc.percent, col = &#39;blue&#39;, pch = 10, xlab = &#39;k&#39;, ylab = &#39;Prosent&#39;, main = &#39;Chebyshevs teorem&#39; ) abline(v=2, col=&quot;red&quot;, lwd = 1) abline(h=75, col=&quot;red&quot;, lwd = 1) Vedlegg 4 Lage ikke-normalfordelte data og plotte Q-Q plott pacman::p_load(ggplot2, tidyverse, magrittr, dplyr, truncnorm) nn &lt;- 1e4 set.seed(1) sims &lt;- as_tibble(c(rtruncnorm(nn/2, a=1, b=5, mean=2, sd=.5), rtruncnorm(nn/2, a=1, b=5, mean=4, sd=.5))) ggplot(sims, aes(sample=value)) + stat_qq() + stat_qq_line(col = &quot;red&quot;) Lage første histogram (populasjonen) pacman::p_load(ggplot2, tidyverse, magrittr, dplyr, truncnorm) nn &lt;- 1e4 set.seed(1) sims &lt;- c(rtruncnorm(nn/2, a=1, b=5, mean=2, sd=.5), rtruncnorm(nn/2, a=1, b=5, mean=4, sd=.5)) mySD &lt;- as.character(abs(as.integer((sims - mean(sims)) / sd(sims)))) myDF &lt;- data.frame(sims, mySD) xAxis &lt;- as.integer(max(abs(sims))) mu &lt;- round(mean(sims),2) sd &lt;- round(sd(sims),2) myBin &lt;- sd/10 ggplot(myDF, aes(sims)) + geom_histogram(aes(fill = mySD), binwidth = myBin, col=&quot;black&quot;, size=.1) + # change binwidth labs(x=&quot;x&quot;, y=&quot;Frequency&quot;) + labs(title=&quot;Histogram av generert bimodal distribusjon&quot;,subtitle=paste0( &quot;Gj.snitt = &quot;, mu, &quot;, sd = &quot;, sd)) + scale_x_continuous(breaks = seq(mu-sd*5, mu+sd*5, sd)) + theme_bw() + theme(plot.title = element_text(hjust = 0.5)) + guides(fill=guide_legend(expression(sigma))) Lage histogram over 100 utvalg av 30 n &lt;- 100 sampSize &lt;- 30 xbar &lt;- rep(NA, n) for (i in 1:n) { mysamp &lt;- sample(sims, size = sampSize) xbar[i] &lt;- mean(mysamp) } mySD&lt;-as.character( abs(as.integer((xbar - mean(xbar)) / sd(xbar) ))) myDF&lt;-data.frame(xbar,mySD) xAxis&lt;-as.integer(max(abs(xbar))) mu&lt;-round(mean(xbar),2) sd&lt;-round(sd(xbar),2) myBin&lt;-sd/10 ggplot(myDF, aes(xbar)) + geom_histogram(aes(fill = mySD), binwidth = myBin, col=&quot;black&quot;, size=.1) + # change binwidth labs(x=&quot;x&quot;, y=&quot;Frequency&quot;) + labs(title=&quot;Histogram for genererte utvalg&quot;, subtitle=paste0( &quot;mean = &quot;, mu, &quot;, sd = &quot;, sd, &quot;, Utvalgsstørrelse = &quot;,sampSize,&quot;, Antall utvalg = &quot;,n))+ scale_x_continuous(breaks = seq(mu-sd*5, mu+sd*5, sd))+ theme_bw()+ theme(plot.title = element_text(hjust = 0.5))+ guides(fill=guide_legend(expression(sigma)))+ geom_density(aes(y=..count../90)) Lage histogram over 1000 utvalg av 30 n&lt;-1000 sampSize&lt;-30 xbar &lt;- rep(NA, n) for (i in 1:n) { mysamp &lt;- sample(sims, size = sampSize) xbar[i] &lt;- mean(mysamp) } mySD&lt;-as.character( abs(as.integer((xbar - mean(xbar)) / sd(xbar) ))) myDF&lt;-data.frame(xbar,mySD) xAxis&lt;-as.integer(max(abs(xbar))) mu&lt;-round(mean(xbar),2) sd&lt;-round(sd(xbar),2) myBin&lt;-sd/10 ggplot(myDF, aes(xbar)) + geom_histogram(aes(fill = mySD), binwidth = myBin, col=&quot;black&quot;, size=.1) + # change binwidth labs(x=&quot;x&quot;, y=&quot;Frequency&quot;) + labs(title=&quot;Histogram for genererte utvalg&quot;, subtitle=paste0( &quot;Gj.snitt = &quot;, mu, &quot;, sd = &quot;, sd, &quot;, Utvalgsstørrelse = &quot;,sampSize,&quot;, Antall utvalg = &quot;,n))+ scale_x_continuous(breaks = seq(mu-sd*5, mu+sd*5, sd))+ theme_bw()+ theme(plot.title = element_text(hjust = 0.5))+ guides(fill=guide_legend(expression(sigma)))+ geom_density(aes(y=..count../90)) Lage histogram over 1000 utvalg av 30 n&lt;-10000 sampSize&lt;-30 xbar &lt;- rep(NA, n) for (i in 1:n) { mysamp &lt;- sample(sims, size = sampSize) xbar[i] &lt;- mean(mysamp) } mySD&lt;-as.character( abs(as.integer((xbar - mean(xbar)) / sd(xbar) ))) myDF&lt;-data.frame(xbar,mySD) xAxis&lt;-as.integer(max(abs(xbar))) mu&lt;-round(mean(xbar),2) sd&lt;-round(sd(xbar),2) myBin&lt;-sd/10 ggplot(myDF, aes(xbar)) + geom_histogram(aes(fill = mySD), binwidth = myBin, col=&quot;black&quot;, size=.1) + # change binwidth labs(x=&quot;x&quot;, y=&quot;Frequency&quot;) + labs(title=&quot;Histogram for genererte utvalg&quot;, subtitle=paste0( &quot;Gj.snitt = &quot;, mu, &quot;, sd = &quot;, sd, &quot;, Utvalgsstørrelsee = &quot;,sampSize,&quot;, Antall utvalg = &quot;,n))+ scale_x_continuous(breaks = seq(mu-sd*5, mu+sd*5, sd))+ theme_bw()+ theme(plot.title = element_text(hjust = 0.5))+ guides(fill=guide_legend(expression(sigma)))+ geom_density(aes(y=..count../90)) Vedlegg 5 pacman::p_load(flextable, SixSigma, officer, magrittr) nmax &lt;- 25 n &lt;- 2:nmax d2 &lt;- sapply(2:nmax, ss.cc.getd2) d3 &lt;- sapply(2:nmax, ss.cc.getd3) c4 &lt;- sapply(2:nmax, ss.cc.getc4) A2 &lt;- 3/(d2*sqrt(n)) D3 &lt;- sapply(1:(nmax-1), function(x){ max(c(0, 1 - 3*(d3[x]/d2[x])))}) D4 &lt;- (1 + 3*(d3/d2)) B3 &lt;- sapply(1:(nmax-1), function(x){ max(0, 1 - 3*(sqrt(1-c4[x]^2)/c4[x]))}) B4 &lt;- 1 + 3*(sqrt(1-c4^2)/c4) constdf &lt;- data.frame(n, A2, d2, d3, c4, D3, D4, B3, B4) set_flextable_defaults(big.mark = &quot; &quot;, font.size = 10, theme_fun = theme_vanilla, padding.bottom = 6, padding.top = 6, padding.left = 6, padding.right = 6, background.color = &quot;#EFEFEF&quot;) constdf1 &lt;- flextable(constdf) constdf1 &lt;- align(constdf1, align = &quot;center&quot;, part = &quot;all&quot;) constdf1 &lt;- add_header_lines(constdf1, values = &quot;Tabell med konstanter for kontrolldiagram&quot;) constdf1 "],["vedlegg-2---kritiske-verdier-i-kontrolldiagram.html", "Vedlegg 2 - Kritiske verdier i kontrolldiagram", " Vedlegg 2 - Kritiske verdier i kontrolldiagram Table 5.1: Kritiske verdier Antall observasjoner Øvre grense for serie Nedre grense for antall krysninger 10 6 2 11 6 2 12 7 3 13 7 3 14 7 4 15 7 4 16 7 4 17 7 5 18 7 5 19 7 6 20 7 6 21 7 6 22 7 7 23 8 7 24 8 8 25 8 8 26 8 8 27 8 9 28 8 9 29 8 10 30 8 10 31 8 11 32 8 11 33 8 11 34 8 12 35 8 12 36 8 13 37 8 13 38 8 14 39 8 14 40 8 14 41 8 15 42 8 15 43 8 16 44 8 16 45 8 17 46 9 17 47 9 17 48 9 18 49 9 18 50 9 19 51 9 19 52 9 20 53 9 20 54 9 21 55 9 21 56 9 21 57 9 22 58 9 22 59 9 23 60 9 23 61 9 24 62 9 24 63 9 25 64 9 25 65 9 25 66 9 26 67 9 26 68 9 27 69 9 27 70 9 28 71 9 28 72 9 29 73 9 29 74 9 29 75 9 30 76 9 30 77 9 31 78 9 31 79 9 32 80 9 32 81 9 33 82 9 33 83 9 34 84 9 34 85 9 34 86 9 35 87 9 35 88 9 36 89 9 36 90 9 37 91 10 37 92 10 38 93 10 38 94 10 39 95 10 39 96 10 39 97 10 40 98 10 40 99 10 41 100 10 41 "],["vedlegg-3---chebyshevs-teorem.html", "Vedlegg 3 - Chebyshevs teorem", " Vedlegg 3 - Chebyshevs teorem Dette vedlegget er i stor grad bygget på Hartmann, Krois, and Waske (2018). Vi diskuterte i noe detalj hvordan vi kan bruke normalfordelingen til å si noe om hvordan verdier i et datasett kan antas å falle innenfor en gitt avstand fra gjennomsnittet (Hartmann, Krois, and Waske 2018): Figure 5.6: Normalfordeling med standardavvik Vi kan ut fra normalfordeingen si at 68 % av observajsonene vil ligge innenfor ett standardavvik fra gjennomsnittsverdien 95 % av observasjonene vil ligge innenfor to standradavvik fra gjennomsnittsverdien 99.7 % av observasjonene vil ligge innenfor tre standardaavik fra gjennomsnittsverdien Dette kalles ofte for den empiriske regelen (the empirical rule), og gjelder kun normalfordelte data. Chebyshevs teorem gjelder imidlertid alle fordelinger. Normalfordelingen gir oss at datapunkter med en viss sannsynlighet ligger innenfor en viss avstand fra gjennomsnittsverdien. Det samme sier Chebyshevs teorem om datafordelinger som ikke er normalfordelte: bare en gitt mengde datapunkter kan ligge mer enn en gitt avstand fra gjennomsnittsverdien. Teoremet uttrykkes slik (Hartmann, Krois, and Waske 2018): For ethvert nummer k større enn 1 vil minst \\(1-1/\\)k\\(^2\\) av dataverdiene ligge innenfor k standardavvik fra gjennomsnittet. Teoremet kan generisk kan framstilles slik: Figure 5.7: Chebyshevs teorem For ethvert numerisk datasett gjelder: Minst ¾ av datapunktene ligger innenfor to standardavvik av gjennomsnittet  altså i intervallet mellom endepunktene \\(\\overline{x}\\pm2s\\) for et utvalg og \\(\\overline{x}\\pm2\\sigma\\) for populasjoner. Minst 8/9 av datapunktene ligger innenfor tre standardavvik av gjennomsnittet  altså i intervallet mellom endepunktene \\(\\overline{x}\\pm3s\\) for et utvalg og \\(\\overline{x}\\pm3\\sigma\\) for populasjoner. Minst \\(1-1/\\)k\\(^2\\) av datapunktene ligger mellom k standardavvik av gjennomsnittet  altså i intervallet mellom endepunktene \\(\\overline{x}\\pm\\)k\\(s\\) for et utvalg og \\(\\overline{x}\\pm\\)k\\(\\sigma\\) for populasjoner. Ut fra tabellen under ser vi at dersom vi velger scroller til k = 2 vil 75 % av verdiene ligge innenfor (altså 75 % innenfor 2 standardavvik). k auc.percent 1.0 0 1.1 17 1.2 31 1.3 41 1.4 49 1.5 56 1.6 61 1.7 65 1.8 69 1.9 72 2.0 75 2.1 77 2.2 79 2.3 81 2.4 83 2.5 84 2.6 85 2.7 86 2.8 87 2.9 88 3.0 89 3.1 90 3.2 90 3.3 91 3.4 91 3.5 92 3.6 92 3.7 93 3.8 93 3.9 93 4.0 94 Vi kan også vise en grafisk framstilling av Chebyshevs teorem med fokus på prosenter (y-aksen) mot k (x-aksen). Figure 5.8: Chebyshevs teorem - prosent Når vi vet at minst 75% av distribusjonen ligger innenfor \\(\\overline{x}\\pm2s\\) vet vi også at maksimalt 25% ligger utenfor. Likeledes for \\(\\overline{x}\\pm3s\\) vil maksimalt 11,11 % av distribusjonen ligge utenfor. Så mens reglene for normalfordeling kun gjelder for normalfordelte eller tilnærmet-normalfordelte datasett, er Chebyshevs teorem et faktum som gjelder alle datadistribusjoner og som beskriver minimumsandelen av observasjoner/datapunkter som ligger innenfor hhv +/- 1, 2 og 3 standardavvik fra gjennomsnittet. "],["vedlegg-4---sentralgrenseteoremet-central-limit-theorem.html", "Vedlegg 4 - Sentralgrenseteoremet (Central Limit Theorem)", " Vedlegg 4 - Sentralgrenseteoremet (Central Limit Theorem) Koden brukt i dette eksempelet er i stor grad hentet fra Fedit (2018) Dette er et noe komplisert begrep som vi ikke skal gå veldig i dybden på, men det har et par viktige konsekvenser for oss når vi skal tenke på distribusjon av populasjoner og utvalg. Her belyser vi to forhold som «gis» av Central Limit Theorem: Gjennomsnittsverdien (mean) av tilfeldige utvalg fra en populasjon vil være tilnærmet lik gjennomsnittsverdien for populasjonen hvis størrelsen på utvalgene er tilstrekkelig stort. Fordelingen til tilfeldige utvalg fra en populasjon vil være tilnærmet normalfordelt uavhengig av fordelingen på populasjonen. Dette innebærer at selv om populasjonen er langt fra normalfordelt vil et tilstrekkelig stort utvalg vise seg å være tilnærmet normalfordelt. La oss se på dette gjennom et eksempel der vi starter med en bimodal fordeling (altså langt fra normalfordeing). Vi generer et datasett og plotter et Q-Q diagram (mer om dette senere i boka, men per nå trenger vi bare vite at dette er en effektiv måte å sjekke om en variabel er normalfordelt eller ikke). Figure 5.9: Ikke-normal fordeling og Q-Q plott Som sagt har vi gjort rede for Q-Q plott et annet sted i boka, så her kan vi nøye oss med å slå fast at denne variabelen definitivt ikke er normalfordelt. Det framkommer også tydelig når vi plotter et histogram: Figure 5.10: Histogram for bimodal fordeling Ut fra denne populasjonen tar vi 100 utvalg med 30 i hvert utvalg. Fordelingen ser da slik ut: Figure 5.11: Histogram for 100 utvalg fra bimodal fordeling Vi kan allerede nå ane en tilnørming mot normalfordeling, og i hvert fall en endret form enn populasjonen viste. Vi tar nå 1000 utvalg med 30 i hvert utvalg. Figure 5.12: Histogram for 1000 utvalg fra bimodal fordeling Det er videre åpenbart at dette begynner å se mer og mer ut som en normalfordeling. Til slutt øker vi til 10000 utvalg av 30. Figure 5.13: Histogram for 10000 utvalg fra bimodal fordeling Det vi kan se bekrefter hva Central Limit Theorem sier vi bør forvente. Vi kan starte med en hvilken som helst fordeling (kontinuerlig eller diskret) som har et definert gjennomsnitt og definert varians (og dermed definert standardavvik) og ta tilfeldige utvalg fra denne fordelingen  og vi vil få en tilnærmet normalfordelt fordeling. I det virkelige liv har vi ofte populasjonsfordelinger som har alt annet enn normalfordeling. Likevel kan vi ta tilfeldige utvalg og få en tilnærmet normalfordelt frekvensplott (av f.eks. gjennomsnittsverdier). Størrelsen på utvalget og antallet ganger vi tar utvalg vil påvirke -&gt; jo større utvalg og jo flere utvalg, jo nærmere normalfordeling vil frekvensplottet være. "],["vedlegg-5---tabell-med-konstanter-for-kontrolldiagram.html", "Vedlegg 5 - Tabell med konstanter for kontrolldiagram", " Vedlegg 5 - Tabell med konstanter for kontrolldiagram .tabwid table{ border-spacing:0px !important; border-collapse:collapse; line-height:1; margin-left:auto; margin-right:auto; border-width: 0; display: table; margin-top: 1.275em; margin-bottom: 1.275em; border-color: transparent; } .tabwid_left table{ margin-left:0; } .tabwid_right table{ margin-right:0; } .tabwid td { padding: 0; } .tabwid a { text-decoration: none; } .tabwid thead { background-color: transparent; } .tabwid tfoot { background-color: transparent; } .tabwid table tr { background-color: transparent; } .cl-fbaae734{}.cl-fb3d7c30{font-family:'Arial';font-size:10pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-fb3d7c31{font-family:'Arial';font-size:10pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-fb43449e{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:6pt;padding-top:6pt;padding-left:6pt;padding-right:6pt;line-height: 1;background-color:transparent;}.cl-fb43449f{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:6pt;padding-top:6pt;padding-left:6pt;padding-right:6pt;line-height: 1;background-color:transparent;}.cl-fb44ca26{width:54pt;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-fb44ca27{width:54pt;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0.5pt solid rgba(102, 102, 102, 1.00);border-top: 0.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-fb44ca28{width:54pt;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-fb44ca29{width:54pt;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 0 solid rgba(255, 255, 255, 0.00);border-top: 0 solid rgba(255, 255, 255, 0.00);border-left: 0 solid rgba(255, 255, 255, 0.00);border-right: 0 solid rgba(255, 255, 255, 0.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-fb44ca2a{width:54pt;background-color:rgba(239, 239, 239, 1.00);vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Tabell med konstanter for kontrolldiagramnA2d2d3c4D3D4B3B421.87997121.1283790.85250250.79788460.000000003.2665320.000000003.26653231.02332671.6925690.88836800.88622690.000000002.5745910.000000002.56817040.72859722.0587510.87980820.92131770.000000002.2820520.000000002.26604750.57681932.3259290.86408190.93998560.000000002.1144990.000000002.08899860.48324602.5344130.84803970.95153290.000000002.0038300.030363211.96963770.41928402.7043570.83320530.95936880.075707741.9242920.117685031.88231580.37252742.8472010.81983110.96503050.136171411.8638290.185089601.81491090.33669742.9700260.80783430.96931070.184013021.8159870.239132801.760867100.30826373.0775050.79705070.97265930.223022661.7769770.283705561.716294110.28508363.1728730.78731460.97535010.255581901.7444180.321280151.678720120.26577793.2584550.77847830.97755940.283269271.7167310.353511831.646488130.24941703.3359800.77041620.97940560.307175601.6928240.381555701.618444140.23535063.4067630.76302310.98097140.328080881.6719190.406245381.593755150.22310923.4718270.75621140.98231620.346558931.6534410.428199541.571800160.21234533.5319830.74990810.98348350.363042131.6369580.447888161.552112170.20279553.5878840.74405180.98450640.377863021.6221370.465675541.534324180.19425673.6400640.73859080.98541000.391281961.6087180.481848961.518151190.18656933.6889630.73348150.98621410.403505971.5964940.496638441.503362200.17960633.7349490.72869080.98693430.414698241.5853020.510230591.489769210.17326513.7783360.72417330.98758290.425006121.5749940.522778621.477221220.16746213.8193850.71991480.98817030.434530791.5654690.534409631.465590230.16212833.8583230.71588680.98870450.443369561.5566300.545230091.454770240.15720613.8953480.71206820.98919270.451601101.5483990.555329931.444670250.15264733.9306290.70844080.98964040.459292041.5407080.564785711.435214 "],["vedlegg-6---utregning-av-kontrollgrenser.html", "Vedlegg 6 - Utregning av kontrollgrenser", " Vedlegg 6 - Utregning av kontrollgrenser Jfr. Laney (2002) og Montgomery (2020) Notasjon Notasjon Innhold CL Sentraltendens (Central Line) UCL Øvre kontrollgrense (Upper Control Limit) LCL Nedre kontrollgrense (Lower Control Limit) n Utvalgsstørrelse \\(\\hat{\\sigma}\\) Standardavvik i prosessen \\(\\overline{x}\\) Gjennomsnitt av målinger \\(\\overline{\\overline{x}}\\) Gjennomsnitt av gjennomsnitt R Spenn (Range) \\(\\hat{R}\\) Gjennomsnitt av spenn (Average of Range) USL Øvre spesifiseringsgrense (Upper Specification Limit) LSL Nedre spesifiseringsgrense (Lower Specification Limit) Måledata Grense X R CL \\[\\overline{\\overline{x}}\\] \\[\\hat{R}\\] UCL \\[\\overline{\\overline{x}} + A_2\\hat{R}\\] \\[\\hat{R}D_4\\] LCL \\[\\overline{\\overline{x}} - A_2\\hat{R}\\] \\[\\hat{R}D_3\\] For A2, D3 og D4: Se vedlegg 5 For IMR (XMR): Grense I MR CL \\[\\overline{x}\\] \\[\\overline{MR}\\] UCL \\[\\overline{x} + 3 \\times \\frac{\\overline{MR}}{d_2}\\] \\[\\overline{MR}D_4\\] LCL \\[\\overline{x} - 3 \\times \\frac{\\overline{MR}}{d_2}\\] Utregning av gjennomsnittlig x-verdi: \\(\\overline{x}\\) = \\(\\frac{\\sum_{i = 1}^{m}x_i}{m}\\) Utregning av Moving Range: \\(MR_i\\) = \\(|x_i-x_i-1|\\), der \\(x_i\\) er et datapunkt og \\(x_i-1\\) er datapunktets foregående datapunkt. Utregning av gjennomsnittlig Moving Range: \\(\\overline{MR}\\) = \\(\\frac{\\sum_{i = 2}^{m}MR_i}{m-1}\\) Attributtdata Grense p np c u CL \\[\\overline{p}\\] \\[n\\overline{p}\\] \\[\\overline{c}\\] \\[\\overline{u}\\] UCL \\[\\overline{p} + 3\\sqrt{\\frac{\\overline{p}(1-\\overline{p})}{n}}\\] \\[n\\overline{p} + 3\\sqrt{n\\overline{p}(1-\\overline{p})}\\] \\[\\overline{c} + 3\\sqrt{\\overline{c}}\\] \\[\\overline{u} + 3\\sqrt{\\frac{\\overline{u}}{n}}\\] LCL \\[\\overline{p} - 3\\sqrt{\\frac{\\overline{p}(1-\\overline{p})}{n}}\\] \\[n\\overline{p} - 3\\sqrt{n\\overline{p}(1-\\overline{p})}\\] \\[\\overline{c} - 3\\sqrt{\\overline{c}}\\] \\[\\overline{u} - 3\\sqrt{\\frac{\\overline{u}}{n}}\\] Grense Laney.p. Laney.u. g CL \\[\\overline{p}\\] \\[\\overline{u}\\] \\[\\overline{g}*0.693\\] UCL \\[\\overline{p} + 3\\sigma_z\\sqrt{\\frac{\\overline{p}(1-\\overline{p})}{n_i}}\\] \\[\\overline{u} + 3\\sigma_z\\sqrt{\\frac{\\overline{u}}{n_i}}\\] \\[\\overline{g} + 3\\sqrt{\\overline{g}(\\overline{g}+1)}\\] LCL \\[\\overline{p} - 3\\sigma_z\\sqrt{\\frac{\\overline{p}(1-\\overline{p})}{n_i}}\\] \\[\\overline{u} - 3\\sigma_z\\sqrt{\\frac{\\overline{u}}{n_i}}\\] \\[\\overline{g} - 3\\sqrt{\\overline{g}(\\overline{g}+1)}\\] z-konvertering for Laneys p: \\(z_i\\) = \\(\\frac{p_i-\\overline{p}}{\\sqrt{\\frac{\\overline{p}(1-\\overline{p})}{n_i}}}\\) z-konvertering for Laneys u: \\(z_i\\) = \\(\\frac{u_i-\\overline{u}}{\\sqrt{\\frac{\\overline{u}}{n_i}}}\\) standardavvik for z: \\(\\sigma_z\\) = \\(\\frac{\\overline{R}}{d_2}\\) MR snitt for Laneys u: \\(M\\overline{R}\\) = \\(\\frac{\\sum{MR}}{(k-1)}\\) "],["vedlegg-7---anderson-darling-test-for-normalitet.html", "Vedlegg 7 - Anderson-Darling test for normalitet", " Vedlegg 7 - Anderson-Darling test for normalitet Jfr. Anderson and Darling (1954), Stephens (1979a), Jäntschi and Bolboac (2018) og Zaiontz (2020) Fordeling AD.verdi Generisk/uniform \\[A=-n-\\frac{1}{n}\\sum_{i=1}^{n}(2_i-1)[lnF(X_i)+ln(1-F(X_{n-i+1}))]\\] Normal/lognormal \\[A^2=A(1+\\frac{75}{n}+\\frac{2.25}{n^2})\\] Gamma \\(k=1\\) \\[A(1+\\frac{6}{n})\\] Gamma \\(k\\ge1\\) \\[A+(\\frac{0.2+\\frac{0.3}{k}}{n})\\] Eksponensiell \\[A(1+\\frac{6}{\\sqrt{n}})\\] Weilbull/Gumbel \\[A(1+\\frac{0.2}{\\sqrt{n}})\\] Logistisk \\[A(1+\\frac{0.25}{\\sqrt{n}})\\] For gammafordeling er k parameteret (shape parameter) definert som \\(\\alpha\\). Kritiske verdier for Anderson-Darling test. Merk: hvis man søker på nett finner man ulike framstillinger med noen avvikende verdier  vi har basert verdiene for normalfordeling på DAgostino and Stephens (1986, 123, tabell 4.7). Øvrige verdier er basert på Marsaglia and Marsaglia (2004) og Stephens (1974, 1976, 1977, 1978, 1979b). Du kan laste ned tabellen i en Excel-fil her: Download AD-alpha.xlsx Tabell over \\(\\alpha\\) verdier "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
